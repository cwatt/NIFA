{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: NIFA\n",
    "\n",
    "Cassandra Wattenburger, 01/06/23\n",
    "\n",
    "### Notes:\n",
    "* QIIME2 v2021.4\n",
    "* Second sequencing attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline information\n",
    "\n",
    "### Pipeline to process raw sequences with DADA2 ###\n",
    "* Prep for import into QIIME2 (modify sequence IDs and combine two index files)\n",
    "* Import into QIIME2\n",
    "* Demultiplex\n",
    "* Denoise and merge with DADA2\n",
    "* Prepare ASV tables and representative sequences *(Note: sample names starting with a digit will break this step)*\n",
    "* Classify sequences\n",
    "* Construct phylogenetic tree\n",
    "* Export from QIIME2\n",
    "\n",
    "*100% Appropriated from the \"Atacama Desert Tutorial\" for QIIME2*\n",
    "\n",
    "### Pipeline can handle both 16S rRNA gene and ITS sequences ###\n",
    "* Tested on 515f and 806r\n",
    "* Tested on ITS1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "\n",
    "### Commands to install dependencies ####\n",
    "##### || QIIME2 and biopython ||\n",
    "QIIME2 is still actively in development with frequent new releases. Check for the most up-to-date version and use that.\n",
    "\n",
    "Install QIIME2: \n",
    "* <https://docs.qiime2.org/2017.11/install/native/#install-qiime-2-within-a-conda-environment>, follow the instructions to install QIIME2 in Linux (64-bit).\n",
    "\n",
    "Activate the QIIME2 environment:\n",
    "* source activate [qiime2-pipeline-name]\n",
    "\n",
    "After you install and activate the QIIME2 environment, you must also install biopython for the barcode concatenation step to work. To install biopython make sure the QIIME2 environment is activated and run:\n",
    "* conda install -c anaconda biopython\n",
    "\n",
    "Install cutadapt to the QIIME2 environment as well. Cutadapt removes primers from the sequences.\n",
    "* conda install -c bioconda cutadapt\n",
    "\n",
    "##### || Copyrighter rrn database ||\n",
    "The script will automatically install the curated GreenGenes rrn attribute database: https://github.com/fangly/AmpliCopyrighter\n",
    "\n",
    "#### Citations\n",
    "* Caporaso, J. G., Kuczynski, J., Stombaugh, J., Bittinger, K., Bushman, F. D., Costello, E. K., *et al.* (2010). QIIME allows analysis of high-throughput community sequencing data. Nature methods, 7(5), 335-336.\n",
    "\n",
    "* Angly, F. E., Dennis, P. G., Skarshewski, A., Vanwonterghem, I., Hugenholtz, P., & Tyson, G. W. (2014). CopyRighter: a rapid tool for improving the accuracy of microbial community profiles through lineage-specific gene copy number correction. Microbiome, 2(1), 11.\n",
    "\n",
    "### Using jupyter notebook screens ###\n",
    "\n",
    "With the QIIME2 environment activated, open your jupyter notebook screen in the directory containing this script:\n",
    "* jupyter-n [screen-name] [port #]\n",
    "\n",
    "See [these instructions](https://github.com/buckleylab/Buckley_lab_protocols/blob/master/Using_the_server/getting_started_on_server.md#make-jupyter-notebook-screens-command) for how to set up and use this command on the server.\n",
    "\n",
    "### Directory and data organization ###\n",
    "\n",
    "This pipeline assumes that you've organized your data in a certain way:\n",
    "* Each library of raw data is contained in a separate directory\n",
    "* Each library has a separate working directory within a larger project directory\n",
    "* Tree construction assumes all 16S libraries processed together will be analyzed together, so one tree is made based on all 16S libraries and is placed in a separate tree directory within the project directory\n",
    "\n",
    "### Troubleshooting tip ###\n",
    "Replace os.system with print, and copy/paste the output into the command line to view the error message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: User Input\n",
    "\n",
    "Metadata requirements:\n",
    "* Must be located in each library directory\n",
    "* Must be .tsv format \n",
    "* First column is named \"SampleID\" with sample names as rows\n",
    "* Contains another column named \"BarcodeSequence\" with the relevant barcode seqeunces as rows (rev. comp. reverse barcode sequence concatenated with forward barcode sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, numpy as np\n",
    "\n",
    "# Prepare an object with the name of the library and all related file paths\n",
    "# datasets = [['library name prefix', 'processed data directory path', 'raw data directory', 'read1 file name', 'read2 file name', 'index1 file name', 'index2 file name', 'metadata file name', 'domain of life (bacteria or fungi)'], ...]\n",
    "project = \"/home/cassi/NIFA/data_amplicon/\" # this can be the same as the library directory if you only have one library to process\n",
    "libraries = [['NIFA2', \n",
    "             '/home/cassi/NIFA/data_amplicon/NIFA2', \n",
    "             '/home/backup_files/raw_reads/NIFA2.Cassi.2023', \n",
    "             '180454_KP85C_NIFA2_library_S1_R1_001.fastq.gz', \n",
    "             '180454_KP85C_NIFA2_library_S1_R2_001.fastq.gz',\n",
    "             '180454_KP85C_NIFA2_library_S1_I1_001.fastq.gz', \n",
    "             '180454_KP85C_NIFA2_library_S1_I2_001.fastq.gz',\n",
    "             'NIFA_demultiplex.tsv',\n",
    "             'bacteria']]\n",
    "\n",
    "# Set # of processors\n",
    "processors = 10\n",
    "\n",
    "# Which bacterial database will you use? Silva or GreenGenes\n",
    "db = \"Silva\"\n",
    "\n",
    "# Phylogenetic tree (non-fungal data)\n",
    "treename = \"NIFA2\" # name prefix for the tree file\n",
    "\n",
    "## Enter minimum support for keeping QIIME classification\n",
    "# Note: Classifications that do not meet this criteria will be retained, labeled 'putative'\n",
    "min_support = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Truncate sequence identifiers\n",
    "\n",
    "This step removes a portion at the end of the sequence ID that is incompatible with QIIME2. It will also create a modified directory in your raw data directory to house the modified data. The original raw data will not be modified, only the copies.\n",
    "\n",
    "Slow step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    read1 = library[3]\n",
    "    read2 = library[4]\n",
    "    index1 = library[5]\n",
    "    index2 = library[6]\n",
    "    \n",
    "    # Create a directory to place modified sequence data\n",
    "    if not os.path.isdir(os.path.join(raw, \"modified\")):\n",
    "        !mkdir $raw/modified\n",
    "    \n",
    "    # Copy/paste all raw sequence data into modified directory\n",
    "    !cp $raw/*.fastq.gz $raw/modified\n",
    "    \n",
    "    # Decompress all files\n",
    "    !unpigz $raw/modified/*.fastq.gz\n",
    "    \n",
    "    # Decompressed file names\n",
    "    read1decomp = re.sub(\".fastq.gz\", \".fastq\", read1)\n",
    "    read2decomp = re.sub(\".fastq.gz\", \".fastq\", read2)\n",
    "    index1decomp = re.sub(\".fastq.gz\", \".fastq\", index1)\n",
    "    index2decomp = re.sub(\".fastq.gz\", \".fastq\", index2)\n",
    "    \n",
    "    # Remove problematic part of sequence IDs\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified/$read1decomp > $raw/modified/read1_mod.fastq\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified/$read2decomp > $raw/modified/read2_mod.fastq\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified/$index1decomp > $raw/modified/index1_mod.fastq\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified/$index2decomp > $raw/modified/index2_mod.fastq\n",
    "    \n",
    "    # Delete file copies\n",
    "    !rm $raw/modified/$read1decomp\n",
    "    !rm $raw/modified/$read2decomp\n",
    "    !rm $raw/modified/$index1decomp\n",
    "    !rm $raw/modified/$index2decomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Remove primer from sequences\n",
    "\n",
    "There may still be portions of the primers left in the read sequences that need to be removed. Use cutadapt to remove those portions. Read1 will have the reverse complement of the reverse primer and read2 will have the reverse complement of the forward primer in some sequences on the 3' end.\n",
    "\n",
    "You will get a warning that the adapter is preceded by \"A\" or \"G\" extremely often. These are the link sequences in the primer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 3.4 with Python 3.8.8\n",
      "Command line parameters: -a ATTAGAWACCCBDGTAGTCC -o /home/backup_files/raw_reads/NIFA2.Cassi.2023/modified/read1_noprimer.fastq /home/backup_files/raw_reads/NIFA2.Cassi.2023/modified/read1_mod.fastq\n",
      "Processing reads on 1 core in single-end mode ...\n",
      "[        8=--] 00:02:38    15,682,286 reads  @     10.1 µs/read;   5.92 M reads/minute\n",
      "Finished in 158.84 s (10 µs/read; 5.92 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:              15,682,286\n",
      "Reads with adapters:                    68,529 (0.4%)\n",
      "Reads written (passing filters):    15,682,286 (100.0%)\n",
      "\n",
      "Total basepairs processed: 3,936,253,786 bp\n",
      "Total written (filtered):  3,934,814,397 bp (100.0%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: ATTAGAWACCCBDGTAGTCC; Type: regular 3'; Length: 20; Trimmed: 68529 times\n",
      "\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-19 bp: 1; 20 bp: 2\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 16.2%\n",
      "  C: 23.6%\n",
      "  G: 41.4%\n",
      "  T: 18.6%\n",
      "  none/other: 0.2%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t37220\t245035.7\t0\t37220\n",
      "4\t9627\t61258.9\t0\t9627\n",
      "5\t2234\t15314.7\t0\t2234\n",
      "6\t1255\t3828.7\t0\t1255\n",
      "7\t552\t957.2\t0\t552\n",
      "8\t500\t239.3\t0\t500\n",
      "9\t438\t59.8\t0\t298 140\n",
      "10\t517\t15.0\t1\t444 73\n",
      "11\t273\t3.7\t1\t229 44\n",
      "12\t292\t0.9\t1\t249 43\n",
      "13\t223\t0.2\t1\t190 33\n",
      "14\t337\t0.1\t1\t286 51\n",
      "15\t209\t0.0\t1\t151 58\n",
      "16\t216\t0.0\t1\t172 44\n",
      "17\t169\t0.0\t1\t140 29\n",
      "18\t318\t0.0\t1\t206 44 68\n",
      "19\t207\t0.0\t1\t181 24 2\n",
      "20\t160\t0.0\t2\t126 24 10\n",
      "21\t146\t0.0\t2\t118 17 11\n",
      "22\t210\t0.0\t2\t167 17 26\n",
      "23\t470\t0.0\t2\t378 57 35\n",
      "24\t514\t0.0\t2\t418 47 49\n",
      "25\t209\t0.0\t2\t162 24 23\n",
      "26\t232\t0.0\t2\t180 35 17\n",
      "27\t696\t0.0\t2\t551 65 80\n",
      "28\t1034\t0.0\t2\t899 97 38\n",
      "29\t505\t0.0\t2\t437 44 24\n",
      "30\t1535\t0.0\t2\t1310 149 76\n",
      "31\t303\t0.0\t2\t240 40 23\n",
      "32\t97\t0.0\t2\t74 18 5\n",
      "33\t157\t0.0\t2\t131 16 10\n",
      "34\t43\t0.0\t2\t37 3 3\n",
      "35\t92\t0.0\t2\t66 11 15\n",
      "36\t211\t0.0\t2\t177 17 17\n",
      "37\t107\t0.0\t2\t86 16 5\n",
      "38\t46\t0.0\t2\t37 1 8\n",
      "39\t68\t0.0\t2\t48 11 9\n",
      "40\t23\t0.0\t2\t17 3 3\n",
      "41\t93\t0.0\t2\t73 12 8\n",
      "42\t386\t0.0\t2\t332 35 19\n",
      "43\t44\t0.0\t2\t31 9 4\n",
      "44\t79\t0.0\t2\t65 9 5\n",
      "45\t81\t0.0\t2\t63 9 9\n",
      "46\t106\t0.0\t2\t82 9 15\n",
      "47\t225\t0.0\t2\t110 15 100\n",
      "48\t151\t0.0\t2\t131 15 5\n",
      "49\t66\t0.0\t2\t49 8 9\n",
      "50\t22\t0.0\t2\t16 5 1\n",
      "51\t29\t0.0\t2\t22 6 1\n",
      "52\t85\t0.0\t2\t68 6 11\n",
      "53\t20\t0.0\t2\t14 3 3\n",
      "54\t8\t0.0\t2\t8\n",
      "55\t82\t0.0\t2\t4 38 40\n",
      "56\t51\t0.0\t2\t13 19 19\n",
      "57\t8\t0.0\t2\t4 1 3\n",
      "58\t16\t0.0\t2\t13 2 1\n",
      "59\t32\t0.0\t2\t16 5 11\n",
      "60\t15\t0.0\t2\t14 0 1\n",
      "61\t204\t0.0\t2\t184 17 3\n",
      "62\t4\t0.0\t2\t3 1\n",
      "63\t6\t0.0\t2\t3 0 3\n",
      "64\t1\t0.0\t2\t0 0 1\n",
      "65\t7\t0.0\t2\t5 0 2\n",
      "66\t17\t0.0\t2\t7 0 10\n",
      "67\t6\t0.0\t2\t1 3 2\n",
      "68\t16\t0.0\t2\t1 0 15\n",
      "69\t8\t0.0\t2\t1 0 7\n",
      "70\t32\t0.0\t2\t11 16 5\n",
      "71\t20\t0.0\t2\t13 4 3\n",
      "72\t7\t0.0\t2\t5 0 2\n",
      "73\t34\t0.0\t2\t2 2 30\n",
      "74\t5\t0.0\t2\t3 0 2\n",
      "75\t4\t0.0\t2\t3 0 1\n",
      "76\t18\t0.0\t2\t8 4 6\n",
      "77\t51\t0.0\t2\t40 6 5\n",
      "78\t3\t0.0\t2\t2 1\n",
      "79\t11\t0.0\t2\t7 1 3\n",
      "80\t5\t0.0\t2\t2 0 3\n",
      "81\t4\t0.0\t2\t2 2\n",
      "82\t1\t0.0\t2\t1\n",
      "84\t36\t0.0\t2\t21 6 9\n",
      "85\t88\t0.0\t2\t72 11 5\n",
      "86\t33\t0.0\t2\t12 3 18\n",
      "87\t92\t0.0\t2\t74 13 5\n",
      "88\t6\t0.0\t2\t2 0 4\n",
      "89\t6\t0.0\t2\t0 1 5\n",
      "90\t2\t0.0\t2\t0 1 1\n",
      "91\t42\t0.0\t2\t5 34 3\n",
      "92\t19\t0.0\t2\t12 2 5\n",
      "93\t1\t0.0\t2\t0 1\n",
      "94\t8\t0.0\t2\t6 0 2\n",
      "95\t3\t0.0\t2\t2 1\n",
      "96\t4\t0.0\t2\t3 1\n",
      "97\t14\t0.0\t2\t4 0 10\n",
      "98\t4\t0.0\t2\t2 0 2\n",
      "99\t5\t0.0\t2\t4 0 1\n",
      "100\t20\t0.0\t2\t19 0 1\n",
      "101\t6\t0.0\t2\t1 4 1\n",
      "102\t6\t0.0\t2\t0 0 6\n",
      "103\t7\t0.0\t2\t3 0 4\n",
      "104\t3\t0.0\t2\t0 3\n",
      "105\t20\t0.0\t2\t14 1 5\n",
      "106\t16\t0.0\t2\t12 2 2\n",
      "107\t6\t0.0\t2\t5 0 1\n",
      "108\t3\t0.0\t2\t1 0 2\n",
      "109\t2\t0.0\t2\t1 0 1\n",
      "110\t19\t0.0\t2\t1 13 5\n",
      "111\t10\t0.0\t2\t4 2 4\n",
      "112\t35\t0.0\t2\t32 2 1\n",
      "113\t12\t0.0\t2\t2 6 4\n",
      "114\t24\t0.0\t2\t15 3 6\n",
      "115\t22\t0.0\t2\t10 10 2\n",
      "116\t5\t0.0\t2\t1 0 4\n",
      "117\t5\t0.0\t2\t1 3 1\n",
      "118\t1\t0.0\t2\t0 0 1\n",
      "119\t7\t0.0\t2\t5 0 2\n",
      "120\t4\t0.0\t2\t1 1 2\n",
      "121\t405\t0.0\t2\t60 9 336\n",
      "122\t30\t0.0\t2\t16 0 14\n",
      "123\t24\t0.0\t2\t0 5 19\n",
      "124\t20\t0.0\t2\t10 3 7\n",
      "125\t2\t0.0\t2\t0 0 2\n",
      "126\t3\t0.0\t2\t1 1 1\n",
      "127\t2\t0.0\t2\t1 0 1\n",
      "128\t13\t0.0\t2\t5 4 4\n",
      "129\t20\t0.0\t2\t0 4 16\n",
      "130\t3\t0.0\t2\t0 0 3\n",
      "131\t14\t0.0\t2\t0 9 5\n",
      "132\t9\t0.0\t2\t0 1 8\n",
      "133\t6\t0.0\t2\t0 4 2\n",
      "134\t6\t0.0\t2\t2 0 4\n",
      "135\t19\t0.0\t2\t3 1 15\n",
      "136\t4\t0.0\t2\t1 3\n",
      "137\t9\t0.0\t2\t2 0 7\n",
      "138\t10\t0.0\t2\t2 1 7\n",
      "139\t7\t0.0\t2\t4 0 3\n",
      "140\t1\t0.0\t2\t0 1\n",
      "141\t14\t0.0\t2\t0 4 10\n",
      "142\t21\t0.0\t2\t0 0 21\n",
      "143\t15\t0.0\t2\t2 0 13\n",
      "144\t138\t0.0\t2\t116 11 11\n",
      "145\t6\t0.0\t2\t3 0 3\n",
      "146\t13\t0.0\t2\t1 4 8\n",
      "147\t7\t0.0\t2\t2 2 3\n",
      "148\t11\t0.0\t2\t0 1 10\n",
      "149\t2\t0.0\t2\t0 0 2\n",
      "150\t12\t0.0\t2\t10 2\n",
      "151\t7\t0.0\t2\t0 4 3\n",
      "152\t34\t0.0\t2\t1 3 30\n",
      "153\t12\t0.0\t2\t0 4 8\n",
      "154\t10\t0.0\t2\t1 2 7\n",
      "155\t3\t0.0\t2\t1 1 1\n",
      "156\t8\t0.0\t2\t3 3 2\n",
      "157\t31\t0.0\t2\t26 1 4\n",
      "158\t33\t0.0\t2\t2 26 5\n",
      "159\t5\t0.0\t2\t1 1 3\n",
      "160\t9\t0.0\t2\t1 4 4\n",
      "161\t8\t0.0\t2\t2 3 3\n",
      "162\t4\t0.0\t2\t0 1 3\n",
      "163\t12\t0.0\t2\t0 9 3\n",
      "164\t25\t0.0\t2\t3 15 7\n",
      "165\t9\t0.0\t2\t0 8 1\n",
      "166\t10\t0.0\t2\t1 2 7\n",
      "167\t8\t0.0\t2\t2 1 5\n",
      "168\t7\t0.0\t2\t0 2 5\n",
      "169\t2\t0.0\t2\t0 0 2\n",
      "170\t3\t0.0\t2\t0 1 2\n",
      "171\t26\t0.0\t2\t2 14 10\n",
      "172\t9\t0.0\t2\t3 2 4\n",
      "173\t15\t0.0\t2\t8 2 5\n",
      "174\t14\t0.0\t2\t9 1 4\n",
      "175\t3\t0.0\t2\t0 0 3\n",
      "176\t7\t0.0\t2\t0 1 6\n",
      "177\t124\t0.0\t2\t91 19 14\n",
      "178\t39\t0.0\t2\t2 33 4\n",
      "179\t5\t0.0\t2\t4 1\n",
      "180\t8\t0.0\t2\t0 5 3\n",
      "181\t6\t0.0\t2\t1 1 4\n",
      "182\t2\t0.0\t2\t0 0 2\n",
      "183\t17\t0.0\t2\t0 1 16\n",
      "184\t10\t0.0\t2\t2 0 8\n",
      "185\t17\t0.0\t2\t9 6 2\n",
      "186\t39\t0.0\t2\t1 26 12\n",
      "187\t21\t0.0\t2\t1 9 11\n",
      "188\t20\t0.0\t2\t5 5 10\n",
      "189\t17\t0.0\t2\t0 12 5\n",
      "190\t15\t0.0\t2\t0 6 9\n",
      "191\t20\t0.0\t2\t2 6 12\n",
      "192\t87\t0.0\t2\t2 3 82\n",
      "193\t23\t0.0\t2\t0 1 22\n",
      "194\t1\t0.0\t2\t0 0 1\n",
      "195\t5\t0.0\t2\t0 2 3\n",
      "196\t142\t0.0\t2\t0 2 140\n",
      "197\t39\t0.0\t2\t35 1 3\n",
      "198\t35\t0.0\t2\t4 13 18\n",
      "199\t5\t0.0\t2\t0 2 3\n",
      "200\t39\t0.0\t2\t0 35 4\n",
      "201\t34\t0.0\t2\t2 1 31\n",
      "202\t11\t0.0\t2\t0 3 8\n",
      "203\t9\t0.0\t2\t0 2 7\n",
      "204\t6\t0.0\t2\t0 2 4\n",
      "205\t44\t0.0\t2\t1 36 7\n",
      "206\t18\t0.0\t2\t0 10 8\n",
      "207\t597\t0.0\t2\t1 4 592\n",
      "208\t16\t0.0\t2\t11 3 2\n",
      "209\t8\t0.0\t2\t2 1 5\n",
      "210\t2\t0.0\t2\t0 0 2\n",
      "211\t276\t0.0\t2\t214 47 15\n",
      "212\t70\t0.0\t2\t46 11 13\n",
      "213\t8\t0.0\t2\t4 2 2\n",
      "214\t2\t0.0\t2\t0 0 2\n",
      "215\t2\t0.0\t2\t1 1\n",
      "216\t13\t0.0\t2\t3 5 5\n",
      "217\t12\t0.0\t2\t0 2 10\n",
      "218\t14\t0.0\t2\t0 1 13\n",
      "219\t4\t0.0\t2\t0 2 2\n",
      "220\t175\t0.0\t2\t7 148 20\n",
      "221\t9\t0.0\t2\t0 2 7\n",
      "222\t51\t0.0\t2\t0 32 19\n",
      "223\t171\t0.0\t2\t4 10 157\n",
      "224\t60\t0.0\t2\t1 5 54\n",
      "225\t51\t0.0\t2\t14 3 34\n",
      "226\t20\t0.0\t2\t3 7 10\n",
      "227\t22\t0.0\t2\t1 1 20\n",
      "228\t11\t0.0\t2\t2 2 7\n",
      "229\t4\t0.0\t2\t0 2 2\n",
      "230\t2\t0.0\t2\t0 1 1\n",
      "231\t29\t0.0\t2\t1 3 25\n",
      "232\t74\t0.0\t2\t13 21 40\n",
      "233\t7\t0.0\t2\t0 2 5\n",
      "234\t13\t0.0\t2\t6 3 4\n",
      "235\t13\t0.0\t2\t2 3 8\n",
      "236\t15\t0.0\t2\t8 1 6\n",
      "237\t13\t0.0\t2\t1 2 10\n",
      "238\t18\t0.0\t2\t4 7 7\n",
      "239\t27\t0.0\t2\t6 1 20\n",
      "240\t6\t0.0\t2\t0 1 5\n",
      "241\t51\t0.0\t2\t29 10 12\n",
      "242\t24\t0.0\t2\t1 2 21\n",
      "243\t26\t0.0\t2\t1 3 22\n",
      "244\t23\t0.0\t2\t0 4 19\n",
      "245\t15\t0.0\t2\t2 5 8\n",
      "246\t21\t0.0\t2\t12 4 5\n",
      "247\t52\t0.0\t2\t33 3 16\n",
      "248\t182\t0.0\t2\t1 7 174\n",
      "249\t13\t0.0\t2\t7 1 5\n",
      "250\t30\t0.0\t2\t10 4 16\n",
      "251\t155\t0.0\t2\t1 138 16\n",
      "This is cutadapt 3.4 with Python 3.8.8\n",
      "Command line parameters: -a TTACCGCGGCKGCTGGCAC -o /home/backup_files/raw_reads/NIFA2.Cassi.2023/modified/read2_noprimer.fastq /home/backup_files/raw_reads/NIFA2.Cassi.2023/modified/read2_mod.fastq\n",
      "Processing reads on 1 core in single-end mode ...\n",
      "[-----=8     ] 00:02:05    15,682,286 reads  @      8.0 µs/read;   7.49 M reads/minute\n",
      "Finished in 125.56 s (8 µs/read; 7.49 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:              15,682,286\n",
      "Reads with adapters:                    61,896 (0.4%)\n",
      "Reads written (passing filters):    15,682,286 (100.0%)\n",
      "\n",
      "Total basepairs processed: 3,936,253,786 bp\n",
      "Total written (filtered):  3,935,611,421 bp (100.0%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: TTACCGCGGCKGCTGGCAC; Type: regular 3'; Length: 19; Trimmed: 61896 times\n",
      "\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-19 bp: 1\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 32.3%\n",
      "  C: 30.2%\n",
      "  G: 15.3%\n",
      "  T: 22.0%\n",
      "  none/other: 0.2%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t30704\t245035.7\t0\t30704\n",
      "4\t14725\t61258.9\t0\t14725\n",
      "5\t5568\t15314.7\t0\t5568\n",
      "6\t611\t3828.7\t0\t611\n",
      "7\t593\t957.2\t0\t593\n",
      "8\t169\t239.3\t0\t169\n",
      "9\t227\t59.8\t0\t211 16\n",
      "10\t376\t15.0\t1\t222 154\n",
      "11\t185\t3.7\t1\t93 92\n",
      "12\t221\t0.9\t1\t141 80\n",
      "13\t168\t0.2\t1\t118 50\n",
      "14\t213\t0.1\t1\t116 97\n",
      "15\t155\t0.0\t1\t108 47\n",
      "16\t140\t0.0\t1\t98 42\n",
      "17\t115\t0.0\t1\t75 40\n",
      "18\t134\t0.0\t1\t27 107\n",
      "19\t135\t0.0\t1\t90 45\n",
      "20\t116\t0.0\t1\t74 42\n",
      "21\t93\t0.0\t1\t60 33\n",
      "22\t123\t0.0\t1\t74 49\n",
      "23\t269\t0.0\t1\t154 115\n",
      "24\t320\t0.0\t1\t78 242\n",
      "25\t144\t0.0\t1\t106 38\n",
      "26\t148\t0.0\t1\t76 72\n",
      "27\t475\t0.0\t1\t306 169\n",
      "28\t793\t0.0\t1\t549 244\n",
      "29\t371\t0.0\t1\t287 84\n",
      "30\t1092\t0.0\t1\t828 264\n",
      "31\t219\t0.0\t1\t149 70\n",
      "32\t61\t0.0\t1\t44 17\n",
      "33\t110\t0.0\t1\t79 31\n",
      "34\t34\t0.0\t1\t21 13\n",
      "35\t54\t0.0\t1\t34 20\n",
      "36\t161\t0.0\t1\t116 45\n",
      "37\t79\t0.0\t1\t54 25\n",
      "38\t35\t0.0\t1\t23 12\n",
      "39\t45\t0.0\t1\t33 12\n",
      "40\t15\t0.0\t1\t12 3\n",
      "41\t61\t0.0\t1\t48 13\n",
      "42\t294\t0.0\t1\t231 63\n",
      "43\t33\t0.0\t1\t21 12\n",
      "44\t55\t0.0\t1\t33 22\n",
      "45\t54\t0.0\t1\t44 10\n",
      "46\t79\t0.0\t1\t57 22\n",
      "47\t108\t0.0\t1\t86 22\n",
      "48\t119\t0.0\t1\t99 20\n",
      "49\t49\t0.0\t1\t41 8\n",
      "50\t14\t0.0\t1\t10 4\n",
      "51\t20\t0.0\t1\t13 7\n",
      "52\t63\t0.0\t1\t48 15\n",
      "53\t14\t0.0\t1\t10 4\n",
      "54\t7\t0.0\t1\t5 2\n",
      "55\t7\t0.0\t1\t6 1\n",
      "56\t8\t0.0\t1\t1 7\n",
      "57\t4\t0.0\t1\t3 1\n",
      "58\t12\t0.0\t1\t11 1\n",
      "59\t9\t0.0\t1\t4 5\n",
      "60\t13\t0.0\t1\t4 9\n",
      "61\t189\t0.0\t1\t166 23\n",
      "62\t3\t0.0\t1\t2 1\n",
      "63\t2\t0.0\t1\t2\n",
      "65\t5\t0.0\t1\t5\n",
      "66\t7\t0.0\t1\t6 1\n",
      "67\t1\t0.0\t1\t0 1\n",
      "68\t2\t0.0\t1\t0 2\n",
      "69\t1\t0.0\t1\t1\n",
      "70\t15\t0.0\t1\t11 4\n",
      "71\t15\t0.0\t1\t12 3\n",
      "72\t4\t0.0\t1\t1 3\n",
      "73\t1\t0.0\t1\t1\n",
      "74\t3\t0.0\t1\t3\n",
      "75\t2\t0.0\t1\t1 1\n",
      "76\t6\t0.0\t1\t3 3\n",
      "77\t42\t0.0\t1\t39 3\n",
      "78\t2\t0.0\t1\t1 1\n",
      "79\t7\t0.0\t1\t7\n",
      "80\t2\t0.0\t1\t2\n",
      "81\t4\t0.0\t1\t2 2\n",
      "82\t1\t0.0\t1\t1\n",
      "84\t22\t0.0\t1\t18 4\n",
      "85\t82\t0.0\t1\t66 16\n",
      "86\t12\t0.0\t1\t11 1\n",
      "87\t76\t0.0\t1\t67 9\n",
      "88\t3\t0.0\t1\t2 1\n",
      "91\t5\t0.0\t1\t4 1\n",
      "92\t12\t0.0\t1\t12\n",
      "94\t7\t0.0\t1\t4 3\n",
      "96\t3\t0.0\t1\t3\n",
      "97\t3\t0.0\t1\t2 1\n",
      "98\t1\t0.0\t1\t1\n",
      "99\t4\t0.0\t1\t4\n",
      "100\t16\t0.0\t1\t13 3\n",
      "101\t1\t0.0\t1\t1\n",
      "103\t4\t0.0\t1\t1 3\n",
      "104\t2\t0.0\t1\t1 1\n",
      "105\t16\t0.0\t1\t12 4\n",
      "106\t13\t0.0\t1\t7 6\n",
      "107\t5\t0.0\t1\t4 1\n",
      "108\t1\t0.0\t1\t0 1\n",
      "111\t8\t0.0\t1\t6 2\n",
      "112\t30\t0.0\t1\t25 5\n",
      "113\t3\t0.0\t1\t2 1\n",
      "114\t17\t0.0\t1\t14 3\n",
      "115\t12\t0.0\t1\t3 9\n",
      "116\t2\t0.0\t1\t0 2\n",
      "117\t3\t0.0\t1\t1 2\n",
      "119\t5\t0.0\t1\t4 1\n",
      "121\t58\t0.0\t1\t56 2\n",
      "122\t22\t0.0\t1\t19 3\n",
      "124\t10\t0.0\t1\t7 3\n",
      "125\t1\t0.0\t1\t0 1\n",
      "126\t1\t0.0\t1\t1\n",
      "127\t1\t0.0\t1\t0 1\n",
      "128\t3\t0.0\t1\t3\n",
      "131\t2\t0.0\t1\t1 1\n",
      "133\t1\t0.0\t1\t0 1\n",
      "134\t3\t0.0\t1\t2 1\n",
      "135\t4\t0.0\t1\t0 4\n",
      "136\t1\t0.0\t1\t0 1\n",
      "137\t2\t0.0\t1\t2\n",
      "138\t3\t0.0\t1\t0 3\n",
      "139\t3\t0.0\t1\t2 1\n",
      "143\t3\t0.0\t1\t1 2\n",
      "144\t116\t0.0\t1\t100 16\n",
      "145\t1\t0.0\t1\t1\n",
      "146\t4\t0.0\t1\t2 2\n",
      "147\t1\t0.0\t1\t1\n",
      "148\t1\t0.0\t1\t0 1\n",
      "150\t8\t0.0\t1\t3 5\n",
      "152\t2\t0.0\t1\t0 2\n",
      "154\t4\t0.0\t1\t2 2\n",
      "155\t2\t0.0\t1\t1 1\n",
      "156\t3\t0.0\t1\t3\n",
      "157\t23\t0.0\t1\t20 3\n",
      "158\t17\t0.0\t1\t12 5\n",
      "159\t2\t0.0\t1\t1 1\n",
      "160\t1\t0.0\t1\t0 1\n",
      "161\t6\t0.0\t1\t3 3\n",
      "163\t1\t0.0\t1\t1\n",
      "164\t8\t0.0\t1\t5 3\n",
      "166\t3\t0.0\t1\t2 1\n",
      "167\t4\t0.0\t1\t3 1\n",
      "168\t1\t0.0\t1\t0 1\n",
      "170\t1\t0.0\t1\t0 1\n",
      "171\t4\t0.0\t1\t2 2\n",
      "172\t4\t0.0\t1\t1 3\n",
      "173\t9\t0.0\t1\t8 1\n",
      "174\t7\t0.0\t1\t1 6\n",
      "177\t118\t0.0\t1\t86 32\n",
      "178\t12\t0.0\t1\t4 8\n",
      "179\t5\t0.0\t1\t3 2\n",
      "180\t4\t0.0\t1\t2 2\n",
      "181\t2\t0.0\t1\t1 1\n",
      "183\t1\t0.0\t1\t0 1\n",
      "184\t3\t0.0\t1\t2 1\n",
      "185\t1\t0.0\t1\t1\n",
      "186\t18\t0.0\t1\t0 18\n",
      "187\t3\t0.0\t1\t0 3\n",
      "188\t6\t0.0\t1\t5 1\n",
      "189\t1\t0.0\t1\t0 1\n",
      "191\t2\t0.0\t1\t2\n",
      "192\t2\t0.0\t1\t2\n",
      "193\t1\t0.0\t1\t0 1\n",
      "194\t1\t0.0\t1\t0 1\n",
      "195\t2\t0.0\t1\t1 1\n",
      "196\t1\t0.0\t1\t1\n",
      "197\t24\t0.0\t1\t10 14\n",
      "198\t12\t0.0\t1\t3 9\n",
      "199\t2\t0.0\t1\t0 2\n",
      "201\t2\t0.0\t1\t0 2\n",
      "202\t2\t0.0\t1\t0 2\n",
      "205\t15\t0.0\t1\t1 14\n",
      "206\t4\t0.0\t1\t3 1\n",
      "207\t1\t0.0\t1\t1\n",
      "208\t7\t0.0\t1\t4 3\n",
      "209\t4\t0.0\t1\t0 4\n",
      "210\t1\t0.0\t1\t0 1\n",
      "211\t6\t0.0\t1\t1 5\n",
      "212\t1\t0.0\t1\t0 1\n",
      "213\t5\t0.0\t1\t2 3\n",
      "214\t2\t0.0\t1\t0 2\n",
      "215\t3\t0.0\t1\t0 3\n",
      "216\t1\t0.0\t1\t1\n",
      "219\t1\t0.0\t1\t0 1\n",
      "220\t78\t0.0\t1\t56 22\n",
      "221\t2\t0.0\t1\t0 2\n",
      "222\t11\t0.0\t1\t0 11\n",
      "223\t4\t0.0\t1\t1 3\n",
      "224\t4\t0.0\t1\t0 4\n",
      "225\t5\t0.0\t1\t0 5\n",
      "226\t7\t0.0\t1\t1 6\n",
      "227\t1\t0.0\t1\t1\n",
      "228\t4\t0.0\t1\t1 3\n",
      "229\t1\t0.0\t1\t1\n",
      "231\t2\t0.0\t1\t1 1\n",
      "232\t22\t0.0\t1\t14 8\n",
      "234\t5\t0.0\t1\t4 1\n",
      "235\t2\t0.0\t1\t0 2\n",
      "236\t8\t0.0\t1\t5 3\n",
      "237\t2\t0.0\t1\t0 2\n",
      "238\t6\t0.0\t1\t3 3\n",
      "239\t7\t0.0\t1\t6 1\n",
      "241\t34\t0.0\t1\t24 10\n",
      "242\t3\t0.0\t1\t1 2\n",
      "243\t4\t0.0\t1\t1 3\n",
      "245\t3\t0.0\t1\t1 2\n",
      "246\t12\t0.0\t1\t11 1\n",
      "247\t2\t0.0\t1\t0 2\n",
      "248\t4\t0.0\t1\t2 2\n",
      "249\t2\t0.0\t1\t1 1\n",
      "250\t8\t0.0\t1\t2 6\n",
      "251\t125\t0.0\t1\t1 124\n"
     ]
    }
   ],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    read1 = library[3]\n",
    "    read2 = library[4]\n",
    "    \n",
    "    !cutadapt -a ATTAGAWACCCBDGTAGTCC -o $raw/modified/read1_noprimer.fastq $raw/modified/read1_mod.fastq\n",
    "    !cutadapt -a TTACCGCGGCKGCTGGCAC -o $raw/modified/read2_noprimer.fastq $raw/modified/read2_mod.fastq\n",
    "    \n",
    "    # Delete unneeded intermediate files\n",
    "    !rm $raw/modified/read*_mod.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Filter short reads\n",
    "\n",
    "Remove sequences with from primer-removed data with less than 100 bp from all files (too short).\n",
    "\n",
    "SLOW STEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    os.system(' '.join([\n",
    "        \"python /home/cassi/scripts/qiime2_filter_shortreads.py\",\n",
    "        raw+\"/modified/\"\n",
    "    ]))\n",
    "    \n",
    "    # Remove unneeded intermediate files\n",
    "    !rm $raw/modified/*_noprimer.fastq\n",
    "    !rm $raw/modified/index*_mod.fastq\n",
    "    \n",
    "    # Recompress modified read files\n",
    "    !pigz $raw/modified/read*_filtered.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Concatenate barcodes\n",
    "\n",
    "This step calls a custom script, \"concatenate_barcodes_qiime2.py\". The script must be shuttled to the command line instead of run directly in jupyter notebooks because jupyter has memory issues that truncates the barcodes file without an error (I think).\n",
    "\n",
    "This script requires your index1 and index2 files to be named index1_mod.fastq and index2_mod.fastq and be located in a directory within the raw read directory called 'modified'. This should have been taken care of in earlier steps in this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"python /home/cassi/scripts/qiime2_concatenate_barcodes.py\",\n",
    "        raw+\"/modified\"]))\n",
    "  \n",
    "    # Recompress modified index files and newly created barcodes.fastq file\n",
    "    !pigz $raw/modified/*.fastq   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Move raw data to library directories\n",
    "\n",
    "Creates intermediate directory in library directory. All subsequent files except for the final files will be placed there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    proc = library[1]\n",
    "    raw = library[2]\n",
    "    \n",
    "    # Create output directory if it doesn't exist already\n",
    "    if not os.path.isdir(os.path.join(proc, \"intermediate\")):\n",
    "        !mkdir $proc/intermediate\n",
    "    \n",
    "    # Create a symbolic link to the read data\n",
    "    # QIIME2 import requires a directory containing files named: forward.fastq.gz, reverse.fastq.gz and barcodes.fastq.gz \n",
    "    !ln -s $raw/modified/read1_filtered.fastq.gz $proc/intermediate/forward.fastq.gz\n",
    "    !ln -s $raw/modified/read2_filtered.fastq.gz $proc/intermediate/reverse.fastq.gz\n",
    "    \n",
    "    # Move concatenated barcodes to project directory\n",
    "    !cp $raw/modified/barcodes.fastq.gz $proc/intermediate/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Import into QIIME2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime tools import\",\n",
    "        \"--type EMPPairedEndSequences\",\n",
    "        \"--input-path \"+proc+\"/intermediate\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"+name+\".qza\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Demultiplex\n",
    "\n",
    "The barcode you supply to QIIME is now a concatenation of your forward and reverse barcode. Your 'forward' barcode is actually the reverse complement of your reverse barcode and the 'reverse' is your forward barcode.\n",
    "\n",
    "Slow step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime demux emp-paired\",\n",
    "        \"--m-barcodes-file \"+proc+\"/\"+metadata,\n",
    "        \"--m-barcodes-column BarcodeSequence\",\n",
    "        \"--p-no-golay-error-correction\",\n",
    "        \"--i-seqs \"+proc+\"/intermediate/\"+name+\".qza\",\n",
    "        \"--o-per-sample-sequences \"+proc+\"/intermediate/\"+name+\".demux\",\n",
    "        \"--o-error-correction-details \"+proc+\"/intermediate/\"+name+\".demux-details.qza\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Visualize quality scores\n",
    "\n",
    "Drop output from below command into https://view.qiime2.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime demux summarize\",\n",
    "        \"--i-data \"+proc+\"/intermediate/\"+name+\".demux.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".demux.qzv\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Trimming parameters | USER INPUT REQUIRED\n",
    "\n",
    "Based on the quality scores of the bp along the reads, choose trim and truncate values for the forward and reverse reads. Trim refers to the start of a sequence and truncate the total length (i.e. number of bases to remove from end).\n",
    "\n",
    "All trimming parameters must be the same for datasets that will be directly compared to one-another because ASVs are determined, in part, by sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input your trimming parameters into a python dictionary for all libraries\n",
    "# trim_dict = {\"LibraryName1\":[trim_forward, truncate_forward, trim_reverse, truncate_reverse],\n",
    "#              \"LibraryName2\":[trim_forward, truncate_forward, trim_reverse, truncate_reverse],\n",
    "#               etc...}\n",
    "\n",
    "# The example in the Atacama Desert Tutorial trims 13 bp from the start of each read and does not remove any bases from the end of the 150 bp reads:\n",
    "#  --p-trim-left-f 13 \\  \n",
    "#  --p-trim-left-r 13 \\\n",
    "#  --p-trunc-len-f 150 \\\n",
    "#  --p-trunc-len-r 150\n",
    "\n",
    "trim_dict = {\"NIFA2\":[10,220,10,220]} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Trim, denoise and join (aka 'merge') reads using DADA2\n",
    "\n",
    "See the [QIIME2 dada2 denoise-paired documentation](https://docs.qiime2.org/2021.8/plugins/available/dada2/denoise-paired/) for the default parameters used.\n",
    "\n",
    "Slow step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime dada2 denoise-paired\",\n",
    "        \"--i-demultiplexed-seqs \"+proc+\"/intermediate/\"+name+\".demux.qza\",\n",
    "        \"--o-table \"+proc+\"/intermediate/\"+name+\".table.qza\",\n",
    "        \"--o-representative-sequences \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "        \"--o-denoising-stats \"+proc+\"/intermediate/\"+name+\".denoising-stats.qza\",\n",
    "        \"--p-trim-left-f \"+str(trim_dict[name][0]),\n",
    "        \"--p-trim-left-r \"+str(trim_dict[name][2]),\n",
    "        \"--p-trunc-len-f \"+str(trim_dict[name][1]),\n",
    "        \"--p-trunc-len-r \"+str(trim_dict[name][3]),\n",
    "        \"--p-n-threads\",\n",
    "        str(processors)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime metadata tabulate\",\n",
    "        \"--m-input-file \"+proc+\"/NIFA/intermediate/\"+name+\".denoising-stats.qza\",\n",
    "        \"--o-visualization \"+proc+\"/NIFA/intermediate/\"+name+\".denoising-stats.qzv\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12: Create summary of ASVs\n",
    "\n",
    "Drop outputs from below command into https://view.qiime2.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime feature-table summarize\",\n",
    "        \"--i-table \"+proc+\"/intermediate/\"+name+\".table.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".table.qzv\",\n",
    "        \"--m-sample-metadata-file \"+proc+\"/\"+metadata\n",
    "    ]))\n",
    "\n",
    "    os.system(' '.join([\n",
    "        \"qiime feature-table tabulate-seqs\",\n",
    "        \"--i-data \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".rep-seqs.qzv\"\n",
    "    ])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 13: Classify sequences\n",
    "\n",
    "Different QIIME2 versions can conflict with certain classifier database versions. This section will likely need to be updated. Download the latest classifiers here: https://docs.qiime2.org/2021.4/data-resources/\n",
    "\n",
    "* Using SILVA v138 pre-built classifier trained on scikit learn 0.24.1.\n",
    "\n",
    "View output in https://view.qiime2.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use classifier for chosen database\n",
    "try:\n",
    "    if db == \"GreenGenes\":\n",
    "        classifier_db = \"/home/db/GreenGenes/qiime2_13.8.99_515.806_nb.classifier.qza\" # out of date\n",
    "    else:\n",
    "        classifier_db = \"~/databases/silva/silva-138-99-515-806-nb-classifier.qza\"\n",
    "except:\n",
    "        classifier_db = \"~/databases/silva/silva-138-99-515-806-nb-classifier.qza\"\n",
    "        \n",
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "    domain = library[8]\n",
    "\n",
    "    # Classify\n",
    "    if domain == 'bacteria':\n",
    "        os.system(' '.join([\n",
    "            \"qiime feature-classifier classify-sklearn\",\n",
    "            \"--i-classifier\",\n",
    "            classifier_db,\n",
    "            \"--i-reads \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "            \"--o-classification \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "            \"--p-n-jobs\",\n",
    "            str(processors)\n",
    "        ]))\n",
    "\n",
    "    if domain == 'fungi':\n",
    "        os.system(' '.join([\n",
    "            \"qiime feature-classifier classify-sklearn\",\n",
    "            \"--i-classifier /home/db/UNITE/qiime2_unite_ver7.99_20.11.2016_classifier.qza\", # out of date\n",
    "            \"--i-reads \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "            \"--o-classification \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "            \"--p-n-jobs\",\n",
    "            str(processors)\n",
    "        ]))\n",
    "\n",
    "    # Output summary\n",
    "    os.system(' '.join([\n",
    "        \"qiime metadata tabulate\",\n",
    "        \"--m-input-file \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".taxonomy-summary.qzv\"\n",
    "    ])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 14: Combine representative sequences for tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bacteria\n",
    "\n",
    "# Create representative sequences file\n",
    "repseqsbac = []\n",
    "\n",
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    domain = library[8]\n",
    "    \n",
    "    # Create list of rep seq files\n",
    "    if domain == \"bacteria\":\n",
    "        repseqsbac.append(\"--i-data \" + os.path.join(proc, \"intermediate\", name+\".rep-seqs.qza\"))\n",
    "\n",
    "# Create tree directory\n",
    "if not os.path.isdir(os.path.join(project, \"tree\")):\n",
    "    !mkdir $project/tree\n",
    "    \n",
    "# Merge rep sequences from all bacterial libraries for tree\n",
    "os.system(' '.join([\n",
    "    \"qiime feature-table merge-seqs\",\n",
    "    \" \".join(repseqsbac),\n",
    "    \"--o-merged-data \"+project+\"/tree/\"+treename+\".rep-seqs-merged.qza\"\n",
    "]))\n",
    "\n",
    "# Fungi\n",
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    domain = library[8]\n",
    "    \n",
    "    # Create representative sequences file\n",
    "    repseqsfung = []\n",
    "    \n",
    "    if domain == \"fungi\":\n",
    "        repseqsfung.append(\"--i-data \" + os.path.join(proc, \"intermediate\", name+\".rep-seqs.qza\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 15: Make phylogenetic tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    domain = library[8]\n",
    "\n",
    "    if domain == \"bacteria\":\n",
    "        # Generate alignment with MAFFT\n",
    "        os.system(' '.join([\n",
    "            \"qiime alignment mafft\",\n",
    "            \"--i-sequences \"+project+\"/tree/\"+treename+\".rep-seqs-merged.qza\",\n",
    "            \"--o-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned.qza\",\n",
    "            \"--p-n-threads\",\n",
    "            str(processors)\n",
    "        ]))\n",
    "\n",
    "        # Mask hypervariable regions in alignment\n",
    "        os.system(' '.join([\n",
    "            \"qiime alignment mask\",\n",
    "            \"--i-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned.qza\",\n",
    "            \"--o-masked-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned-masked.qza\",\n",
    "        ]))\n",
    "\n",
    "        # Generate tree with FastTree\n",
    "        os.system(' '.join([\n",
    "            \"qiime phylogeny fasttree\",\n",
    "            \"--i-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned-masked.qza\",\n",
    "            \"--o-tree \"+project+\"/tree/\"+treename+\".tree-unrooted.qza\",\n",
    "            \"--p-n-threads\",\n",
    "            str(processors)\n",
    "        ]))\n",
    "\n",
    "        # Root the tree\n",
    "        os.system(' '.join([\n",
    "            \"qiime phylogeny midpoint-root\",\n",
    "            \"--i-tree \"+project+\"/tree/\"+treename+\".tree-unrooted.qza\",\n",
    "            \"--o-rooted-tree \"+project+\"/tree/\"+treename+\".tree-rooted.qza\"\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 16: Reformat taxonomy\n",
    "\n",
    "Define function to tidy the taxonomy and make it compatible with phyloseq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_taxonomy(tax_dirty, min_support):\n",
    "    output = open(re.sub(\".tsv\",\"-fixed.tsv\",tax_dirty), \"w\")\n",
    "    \n",
    "    full_rank_length = 7\n",
    "    output.write(\"\\t\".join([\"ASV\",\"Domain\",\"Phylum\",\"Class\",\"Order\",\"Family\",\"Genus\",\"Species\"])+\"\\n\")\n",
    "\n",
    "    with open(tax_dirty, \"r\") as f:\n",
    "        next(f)\n",
    "\n",
    "        for line in f:\n",
    "                line = line.strip()\n",
    "                line = line.split(\"\\t\")\n",
    "\n",
    "                read_id = line[0]\n",
    "                tax_string = line[1]\n",
    "                \n",
    "                ## Remove taxonomy prefixes and underscores (only coded for Silva classifications so far)\n",
    "                if db == \"Silva\":\n",
    "                    tax_string = re.sub(\"[a-z]__\", \"\", tax_string)\n",
    "                    tax_string = re.sub(\"_\", \" \", tax_string)\n",
    "\n",
    "                # Split full rank into ranks\n",
    "                full_rank = tax_string.split(\";\")\n",
    "\n",
    "                ## Identify the lowest classified taxonomic rank\n",
    "                # Account for cases when a taxonomic rank contains an empty space (common in GreenGenes output)\n",
    "                last_classified = full_rank[len(full_rank)-1]            \n",
    "\n",
    "                count = 1\n",
    "                while last_classified == \" \":\n",
    "                    last_classified = full_rank[len(full_rank)-count]\n",
    "                    count = count + 1\n",
    "\n",
    "                # Annotate the last classified as 'putative' if it does not meet the minimum support criteria\n",
    "                if float(line[2]) < float(min_support):\n",
    "                        full_rank[full_rank.index(last_classified)] = \"putative \"+last_classified\n",
    "                        last_classified = \"putative \"+last_classified\n",
    "\n",
    "                # Add in columns containing unclassified taxonomic information\n",
    "                for n in range(full_rank.index(last_classified)+1, full_rank_length, 1):               \n",
    "                    try:\n",
    "                        full_rank[n] = \"unclassified \"+last_classified\n",
    "                    except:\n",
    "                        full_rank.append(\"unclassified \"+last_classified)\n",
    "\n",
    "                # Write taxonomy to file\n",
    "                output.write(read_id+\"\\t\"+'\\t'.join(full_rank)+\"\\n\")\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 17: Export from QIIME2\n",
    "\n",
    "All final files will be placed in 'final' directory in library directories. Final tree will be in a 'tree' directory in the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "\n",
    "    # Final output paths\n",
    "    fasta_final = proc+\"/final/\"+name+\".rep-seqs-final.fasta\"\n",
    "    tax_final= proc+\"/final/\"+name+\".taxonomy-final.tsv\"\n",
    "    count_final = proc+\"/final/\"+name+\".counts-final.biom\"\n",
    "    \n",
    "    # Make final data directories\n",
    "    if not os.path.isdir(os.path.join(proc, \"final\")):\n",
    "        !mkdir $proc/final\n",
    "        \n",
    "    # Export ASV table\n",
    "    os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+proc+\"/intermediate/\"+name+\".table.qza\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"\n",
    "    ]))\n",
    "\n",
    "    # Export taxonomic classifications\n",
    "    os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"\n",
    "    ]))\n",
    "    \n",
    "    # Reformat classifications  \n",
    "    format_taxonomy(proc+\"/intermediate/taxonomy.tsv\", min_support)\n",
    "\n",
    "    # Export representative sequences\n",
    "    os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"\n",
    "    ]))\n",
    "    \n",
    "    # Rename exported files and move to final directory\n",
    "    !mv $proc/intermediate/dna-sequences.fasta $fasta_final\n",
    "    !mv $proc/intermediate/feature-table.biom $count_final\n",
    "    !mv $proc/intermediate/taxonomy-fixed.tsv $tax_final\n",
    "    \n",
    "    # Reformat count table\n",
    "    tmp_tsv = re.sub(name+\".counts-final.biom\", \"tmp.tsv\", count_final)\n",
    "    tmp2_tsv = re.sub(name+\".counts-final.biom\", \"tmp2.tsv\", count_final)\n",
    "    count_tsv = re.sub(\".biom\", \".tsv\", count_final)\n",
    "    !biom convert -i $count_final -o $tmp_tsv --to-tsv # conver to .tsv\n",
    "    !tail -n +2 $tmp_tsv > $tmp2_tsv # remove header\n",
    "    !sed 's/\\#OTU ID/ASV/g' $tmp2_tsv > $count_tsv # replace OTU with ASV\n",
    "    !rm $tmp_tsv\n",
    "    !rm $tmp2_tsv\n",
    "    \n",
    "# Export tree\n",
    "os.system(' '.join([\n",
    "    \"qiime tools export\",\n",
    "    \"--input-path \"+project+\"/tree/\"+treename+\".tree-rooted.qza\",\n",
    "    \"--output-path \"+project+\"/tree/\"\n",
    "]))\n",
    "\n",
    "# Rename tree file\n",
    "tree_final = project+\"/tree/\"+treename+\".tree-final.nwk\"\n",
    "!mv $project/tree/\"tree.nwk\" $tree_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export tree\n",
    "os.system(' '.join([\n",
    "    \"qiime tools export\",\n",
    "    \"--input-path \"+project+\"/tree/\"+treename+\".tree-rooted.qza\",\n",
    "    \"--output-path \"+project+\"/tree/\"\n",
    "]))\n",
    "\n",
    "# Rename tree file\n",
    "tree_final = project+\"/tree/\"+treename+\".tree-final.nwk\"\n",
    "!mv $project/tree/\"tree.nwk\" $tree_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export merged rep seqs\n",
    "os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+project+\"/tree/\"+treename+\".rep-seqs-merged.qza\",\n",
    "        \"--output-path \"+project+\"/tree/\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
