{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: NIFA\n",
    "\n",
    "Cassandra Wattenburger, 09/26/2022\n",
    "\n",
    "### Notes:\n",
    "* QIIME2 v2021.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline information\n",
    "\n",
    "### Pipeline to process raw sequences with DADA2 ###\n",
    "* Prep for import into QIIME2 (modify sequence IDs and combine two index files)\n",
    "* Import into QIIME2\n",
    "* Demultiplex\n",
    "* Denoise and merge with DADA2\n",
    "* Prepare ASV tables and representative sequences *(Note: sample names starting with a digit will break this step)*\n",
    "* Classify sequences\n",
    "* Construct phylogenetic tree\n",
    "* Export from QIIME2\n",
    "\n",
    "*100% Appropriated from the \"Atacama Desert Tutorial\" for QIIME2*\n",
    "\n",
    "### Pipeline can handle both 16S rRNA gene and ITS sequences ###\n",
    "* Tested on 515f and 806r\n",
    "* Tested on ITS1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "\n",
    "### Commands to install dependencies ####\n",
    "##### || QIIME2 and biopython ||\n",
    "QIIME2 is still actively in development with frequent new releases. Check for the most up-to-date version and use that.\n",
    "\n",
    "Install QIIME2: \n",
    "* <https://docs.qiime2.org/2017.11/install/native/#install-qiime-2-within-a-conda-environment>, follow the instructions to install QIIME2 in Linux (64-bit).\n",
    "\n",
    "Activate the QIIME2 environment:\n",
    "* source activate [qiime2-pipeline-name]\n",
    "\n",
    "After you install and activate the QIIME2 environment, you must also install biopython for the barcode concatenation step to work. To install biopython make sure the QIIME2 environment is activated and run:\n",
    "* conda install -c anaconda biopython\n",
    "\n",
    "Install cutadapt to the QIIME2 environment as well. Cutadapt removes primers from the sequences.\n",
    "* conda install -c bioconda cutadapt\n",
    "\n",
    "##### || Copyrighter rrn database ||\n",
    "The script will automatically install the curated GreenGenes rrn attribute database: https://github.com/fangly/AmpliCopyrighter\n",
    "\n",
    "#### Citations\n",
    "* Caporaso, J. G., Kuczynski, J., Stombaugh, J., Bittinger, K., Bushman, F. D., Costello, E. K., *et al.* (2010). QIIME allows analysis of high-throughput community sequencing data. Nature methods, 7(5), 335-336.\n",
    "\n",
    "* Angly, F. E., Dennis, P. G., Skarshewski, A., Vanwonterghem, I., Hugenholtz, P., & Tyson, G. W. (2014). CopyRighter: a rapid tool for improving the accuracy of microbial community profiles through lineage-specific gene copy number correction. Microbiome, 2(1), 11.\n",
    "\n",
    "### Using jupyter notebook screens ###\n",
    "\n",
    "With the QIIME2 environment activated, open your jupyter notebook screen in the directory containing this script:\n",
    "* jupyter-n [screen-name] [port #]\n",
    "\n",
    "See [these instructions](https://github.com/buckleylab/Buckley_lab_protocols/blob/master/Using_the_server/getting_started_on_server.md#make-jupyter-notebook-screens-command) for how to set up and use this command on the server.\n",
    "\n",
    "### Directory and data organization ###\n",
    "\n",
    "This pipeline assumes that you've organized your data in a certain way:\n",
    "* Each library of raw data is contained in a separate directory\n",
    "* Each library has a separate working directory within a larger project directory\n",
    "* Tree construction assumes all 16S libraries processed together will be analyzed together, so one tree is made based on all 16S libraries and is placed in a separate tree directory within the project directory\n",
    "\n",
    "### Troubleshooting tip ###\n",
    "Replace os.system with print, and copy/paste the output into the command line to view the error message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: User Input\n",
    "\n",
    "Metadata requirements:\n",
    "* Must be located in each library directory\n",
    "* Must be .tsv format \n",
    "* First column is named \"SampleID\" with sample names as rows\n",
    "* Contains another column named \"BarcodeSequence\" with the relevant barcode seqeunces as rows (rev. comp. reverse barcode sequence concatenated with forward barcode sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, numpy as np\n",
    "\n",
    "# Prepare an object with the name of the library and all related file paths\n",
    "# datasets = [['library name prefix', 'processed data directory path', 'raw data directory', 'read1 file name', 'read2 file name', 'index1 file name', 'index2 file name', 'metadata file name', 'domain of life (bacteria or fungi)'], ...]\n",
    "project = \"/home/cassi/NIFA/data_amplicon\" # this can be the same as the library directory if you only have one library to process\n",
    "libraries = [['NIFA', \n",
    "             '/home/cassi/NIFA/data_amplicon/NIFA', \n",
    "             '/home/backup_files/raw_reads/NIFA.Cassi.2022',\n",
    "             '170932_KLGRY_NIFA_S1_R1_001.fastq.gz', \n",
    "             '170932_KLGRY_NIFA_S1_R2_001.fastq.gz', \n",
    "             '170932_KLGRY_NIFA_S1_I1_001.fastq.gz', \n",
    "             '170932_KLGRY_NIFA_S1_I2_001.fastq.gz', \n",
    "             'NIFA_demultiplex.tsv',\n",
    "             'bacteria']]\n",
    "\n",
    "# Set # of processors\n",
    "processors = 10\n",
    "\n",
    "# Which bacterial database will you use? Silva or GreenGenes\n",
    "db = \"Silva\"\n",
    "\n",
    "# Phylogenetic tree (non-fungal data)\n",
    "treename = \"NIFA\" # name prefix for the tree file\n",
    "\n",
    "## Enter minimum support for keeping QIIME classification\n",
    "# Note: Classifications that do not meet this criteria will be retained, labeled 'putative'\n",
    "min_support = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Truncate sequence identifiers\n",
    "\n",
    "This step removes a portion at the end of the sequence ID that is incompatible with QIIME2. It will also create a modified directory in your raw data directory to house the modified data. The original raw data will not be modified, only the copies.\n",
    "\n",
    "Slow step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    read1 = library[3]\n",
    "    read2 = library[4]\n",
    "    index1 = library[5]\n",
    "    index2 = library[6]\n",
    "    \n",
    "    # Create a directory to place modified sequence data\n",
    "    if not os.path.isdir(os.path.join(raw, \"modified\")):\n",
    "        !mkdir $raw/modified\n",
    "    \n",
    "    # Copy/paste all raw sequence data into modified directory\n",
    "    !cp $raw/*.fastq.gz $raw/modified\n",
    "    \n",
    "    # Decompress all files\n",
    "    !unpigz $raw/modified/*.fastq.gz\n",
    "    \n",
    "    # Decompressed file names\n",
    "    read1decomp = re.sub(\".fastq.gz\", \".fastq\", read1)\n",
    "    read2decomp = re.sub(\".fastq.gz\", \".fastq\", read2)\n",
    "    index1decomp = re.sub(\".fastq.gz\", \".fastq\", index1)\n",
    "    index2decomp = re.sub(\".fastq.gz\", \".fastq\", index2)\n",
    "    \n",
    "    # Remove problematic part of sequence IDs\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified/$read1decomp > $raw/modified/read1_mod.fastq\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified/$read2decomp > $raw/modified/read2_mod.fastq\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified/$index1decomp > $raw/modified/index1_mod.fastq\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified/$index2decomp > $raw/modified/index2_mod.fastq\n",
    "    \n",
    "    # Delete file copies\n",
    "    !rm $raw/modified/$read1decomp\n",
    "    !rm $raw/modified/$read2decomp\n",
    "    !rm $raw/modified/$index1decomp\n",
    "    !rm $raw/modified/$index2decomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Remove primer from sequences\n",
    "\n",
    "There may still be portions of the primers left in the read sequences that need to be removed. Use cutadapt to remove those portions. Read1 will have the reverse complement of the reverse primer and read2 will have the reverse complement of the forward primer in some sequences on the 3' end.\n",
    "\n",
    "You will get a warning that the adapter is preceded by \"A\" or \"G\" extremely often. These are the link sequences in the primer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 3.4 with Python 3.8.8\n",
      "Command line parameters: -a ATTAGAWACCCBDGTAGTCC -o /home/backup_files/raw_reads/NIFA.Cassi.2022/modified/read1_noprimer.fastq /home/backup_files/raw_reads/NIFA.Cassi.2022/modified/read1_mod.fastq\n",
      "Processing reads on 1 core in single-end mode ...\n",
      "[--=8        ] 00:02:54    17,197,051 reads  @     10.1 µs/read;   5.93 M reads/minute\n",
      "Finished in 174.03 s (10 µs/read; 5.93 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:              17,197,051\n",
      "Reads with adapters:                    92,105 (0.5%)\n",
      "Reads written (passing filters):    17,197,051 (100.0%)\n",
      "\n",
      "Total basepairs processed: 4,316,459,801 bp\n",
      "Total written (filtered):  4,314,935,691 bp (100.0%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: ATTAGAWACCCBDGTAGTCC; Type: regular 3'; Length: 20; Trimmed: 92105 times\n",
      "\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-19 bp: 1; 20 bp: 2\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 19.1%\n",
      "  C: 25.0%\n",
      "  G: 36.9%\n",
      "  T: 19.0%\n",
      "  none/other: 0.0%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t53231\t268703.9\t0\t53231\n",
      "4\t15996\t67176.0\t0\t15996\n",
      "5\t3551\t16794.0\t0\t3551\n",
      "6\t1926\t4198.5\t0\t1926\n",
      "7\t462\t1049.6\t0\t462\n",
      "8\t523\t262.4\t0\t523\n",
      "9\t423\t65.6\t0\t229 194\n",
      "10\t330\t16.4\t1\t276 54\n",
      "11\t108\t4.1\t1\t87 21\n",
      "12\t149\t1.0\t1\t138 11\n",
      "13\t69\t0.3\t1\t59 10\n",
      "14\t249\t0.1\t1\t228 21\n",
      "15\t87\t0.0\t1\t71 16\n",
      "16\t27\t0.0\t1\t15 12\n",
      "17\t21\t0.0\t1\t20 1\n",
      "18\t218\t0.0\t1\t129 23 66\n",
      "19\t24\t0.0\t1\t19 3 2\n",
      "20\t37\t0.0\t2\t23 6 8\n",
      "21\t20\t0.0\t2\t16 4\n",
      "22\t54\t0.0\t2\t47 4 3\n",
      "23\t426\t0.0\t2\t353 54 19\n",
      "24\t495\t0.0\t2\t433 33 29\n",
      "25\t140\t0.0\t2\t117 11 12\n",
      "26\t210\t0.0\t2\t158 32 20\n",
      "27\t696\t0.0\t2\t550 73 73\n",
      "28\t1548\t0.0\t2\t1338 140 70\n",
      "29\t670\t0.0\t2\t570 69 31\n",
      "30\t1899\t0.0\t2\t1644 181 74\n",
      "31\t460\t0.0\t2\t389 51 20\n",
      "32\t47\t0.0\t2\t33 10 4\n",
      "33\t175\t0.0\t2\t146 17 12\n",
      "34\t31\t0.0\t2\t26 5\n",
      "35\t20\t0.0\t2\t17 2 1\n",
      "36\t152\t0.0\t2\t129 15 8\n",
      "37\t19\t0.0\t2\t16 1 2\n",
      "38\t37\t0.0\t2\t31 4 2\n",
      "39\t20\t0.0\t2\t12 2 6\n",
      "40\t13\t0.0\t2\t10 1 2\n",
      "41\t83\t0.0\t2\t64 9 10\n",
      "42\t450\t0.0\t2\t391 43 16\n",
      "43\t12\t0.0\t2\t10 1 1\n",
      "44\t67\t0.0\t2\t56 7 4\n",
      "45\t106\t0.0\t2\t92 11 3\n",
      "46\t120\t0.0\t2\t87 7 26\n",
      "47\t403\t0.0\t2\t194 12 197\n",
      "48\t191\t0.0\t2\t162 20 9\n",
      "49\t61\t0.0\t2\t53 6 2\n",
      "50\t19\t0.0\t2\t15 2 2\n",
      "51\t25\t0.0\t2\t16 4 5\n",
      "52\t81\t0.0\t2\t70 6 5\n",
      "53\t10\t0.0\t2\t9 0 1\n",
      "54\t4\t0.0\t2\t2 2\n",
      "55\t49\t0.0\t2\t6 21 22\n",
      "56\t31\t0.0\t2\t11 10 10\n",
      "57\t14\t0.0\t2\t11 1 2\n",
      "58\t7\t0.0\t2\t5 1 1\n",
      "59\t28\t0.0\t2\t18 4 6\n",
      "60\t29\t0.0\t2\t23 3 3\n",
      "61\t315\t0.0\t2\t287 22 6\n",
      "62\t9\t0.0\t2\t5 2 2\n",
      "63\t4\t0.0\t2\t0 3 1\n",
      "64\t8\t0.0\t2\t4 1 3\n",
      "65\t8\t0.0\t2\t6 0 2\n",
      "66\t20\t0.0\t2\t14 1 5\n",
      "67\t8\t0.0\t2\t0 2 6\n",
      "68\t11\t0.0\t2\t2 0 9\n",
      "69\t2\t0.0\t2\t0 2\n",
      "70\t53\t0.0\t2\t15 32 6\n",
      "71\t23\t0.0\t2\t21 2\n",
      "72\t8\t0.0\t2\t4 3 1\n",
      "73\t38\t0.0\t2\t3 1 34\n",
      "74\t7\t0.0\t2\t3 1 3\n",
      "75\t2\t0.0\t2\t0 1 1\n",
      "76\t11\t0.0\t2\t11\n",
      "77\t57\t0.0\t2\t48 2 7\n",
      "78\t19\t0.0\t2\t14 2 3\n",
      "79\t8\t0.0\t2\t2 2 4\n",
      "80\t6\t0.0\t2\t6\n",
      "81\t4\t0.0\t2\t2 1 1\n",
      "82\t8\t0.0\t2\t5 2 1\n",
      "83\t4\t0.0\t2\t2 2\n",
      "84\t40\t0.0\t2\t22 5 13\n",
      "85\t89\t0.0\t2\t73 11 5\n",
      "86\t65\t0.0\t2\t40 6 19\n",
      "87\t142\t0.0\t2\t126 8 8\n",
      "88\t10\t0.0\t2\t1 0 9\n",
      "89\t4\t0.0\t2\t0 0 4\n",
      "90\t8\t0.0\t2\t6 1 1\n",
      "91\t21\t0.0\t2\t0 16 5\n",
      "92\t5\t0.0\t2\t0 0 5\n",
      "93\t1\t0.0\t2\t0 1\n",
      "94\t12\t0.0\t2\t5 5 2\n",
      "95\t7\t0.0\t2\t4 1 2\n",
      "96\t11\t0.0\t2\t7 2 2\n",
      "97\t12\t0.0\t2\t6 1 5\n",
      "98\t3\t0.0\t2\t1 2\n",
      "99\t7\t0.0\t2\t4 1 2\n",
      "100\t28\t0.0\t2\t23 3 2\n",
      "101\t7\t0.0\t2\t3 2 2\n",
      "102\t7\t0.0\t2\t2 4 1\n",
      "103\t5\t0.0\t2\t0 0 5\n",
      "104\t1\t0.0\t2\t0 0 1\n",
      "105\t34\t0.0\t2\t23 1 10\n",
      "106\t28\t0.0\t2\t17 2 9\n",
      "107\t16\t0.0\t2\t7 1 8\n",
      "108\t1\t0.0\t2\t0 0 1\n",
      "109\t5\t0.0\t2\t1 0 4\n",
      "110\t30\t0.0\t2\t9 15 6\n",
      "111\t5\t0.0\t2\t1 1 3\n",
      "112\t8\t0.0\t2\t4 0 4\n",
      "113\t6\t0.0\t2\t2 4\n",
      "114\t35\t0.0\t2\t28 3 4\n",
      "115\t25\t0.0\t2\t11 10 4\n",
      "116\t10\t0.0\t2\t4 0 6\n",
      "117\t9\t0.0\t2\t4 2 3\n",
      "118\t2\t0.0\t2\t1 0 1\n",
      "119\t8\t0.0\t2\t3 2 3\n",
      "120\t7\t0.0\t2\t2 0 5\n",
      "121\t492\t0.0\t2\t85 15 392\n",
      "122\t51\t0.0\t2\t39 6 6\n",
      "123\t14\t0.0\t2\t0 0 14\n",
      "124\t25\t0.0\t2\t15 1 9\n",
      "125\t5\t0.0\t2\t1 3 1\n",
      "126\t1\t0.0\t2\t1\n",
      "127\t1\t0.0\t2\t0 0 1\n",
      "128\t2\t0.0\t2\t0 2\n",
      "129\t20\t0.0\t2\t0 3 17\n",
      "130\t8\t0.0\t2\t2 0 6\n",
      "131\t7\t0.0\t2\t0 2 5\n",
      "132\t11\t0.0\t2\t0 4 7\n",
      "133\t1\t0.0\t2\t0 1\n",
      "134\t2\t0.0\t2\t0 0 2\n",
      "135\t16\t0.0\t2\t2 3 11\n",
      "136\t4\t0.0\t2\t0 0 4\n",
      "137\t7\t0.0\t2\t3 0 4\n",
      "138\t4\t0.0\t2\t1 0 3\n",
      "139\t5\t0.0\t2\t3 0 2\n",
      "140\t5\t0.0\t2\t2 1 2\n",
      "141\t9\t0.0\t2\t2 3 4\n",
      "142\t20\t0.0\t2\t0 1 19\n",
      "143\t17\t0.0\t2\t0 3 14\n",
      "144\t190\t0.0\t2\t153 20 17\n",
      "145\t14\t0.0\t2\t6 4 4\n",
      "146\t19\t0.0\t2\t1 13 5\n",
      "147\t8\t0.0\t2\t2 4 2\n",
      "148\t20\t0.0\t2\t0 11 9\n",
      "149\t3\t0.0\t2\t0 1 2\n",
      "150\t4\t0.0\t2\t3 0 1\n",
      "151\t15\t0.0\t2\t2 8 5\n",
      "152\t23\t0.0\t2\t1 0 22\n",
      "153\t3\t0.0\t2\t1 1 1\n",
      "154\t7\t0.0\t2\t2 0 5\n",
      "155\t3\t0.0\t2\t1 0 2\n",
      "156\t7\t0.0\t2\t1 3 3\n",
      "157\t16\t0.0\t2\t12 1 3\n",
      "158\t38\t0.0\t2\t1 25 12\n",
      "159\t5\t0.0\t2\t2 3\n",
      "160\t12\t0.0\t2\t0 11 1\n",
      "161\t5\t0.0\t2\t0 1 4\n",
      "162\t5\t0.0\t2\t2 0 3\n",
      "163\t15\t0.0\t2\t1 6 8\n",
      "164\t21\t0.0\t2\t2 9 10\n",
      "165\t12\t0.0\t2\t0 8 4\n",
      "166\t6\t0.0\t2\t0 1 5\n",
      "167\t13\t0.0\t2\t0 3 10\n",
      "168\t6\t0.0\t2\t0 4 2\n",
      "169\t8\t0.0\t2\t3 2 3\n",
      "170\t5\t0.0\t2\t0 3 2\n",
      "171\t19\t0.0\t2\t2 11 6\n",
      "172\t5\t0.0\t2\t3 0 2\n",
      "173\t23\t0.0\t2\t16 2 5\n",
      "174\t18\t0.0\t2\t9 5 4\n",
      "175\t6\t0.0\t2\t4 0 2\n",
      "176\t2\t0.0\t2\t0 0 2\n",
      "177\t129\t0.0\t2\t97 13 19\n",
      "178\t37\t0.0\t2\t2 31 4\n",
      "179\t6\t0.0\t2\t0 1 5\n",
      "180\t4\t0.0\t2\t0 2 2\n",
      "181\t9\t0.0\t2\t2 5 2\n",
      "182\t2\t0.0\t2\t1 0 1\n",
      "183\t20\t0.0\t2\t1 4 15\n",
      "184\t4\t0.0\t2\t0 0 4\n",
      "185\t16\t0.0\t2\t10 6\n",
      "186\t26\t0.0\t2\t1 15 10\n",
      "187\t16\t0.0\t2\t1 6 9\n",
      "188\t26\t0.0\t2\t13 2 11\n",
      "189\t17\t0.0\t2\t2 5 10\n",
      "190\t14\t0.0\t2\t0 2 12\n",
      "191\t17\t0.0\t2\t3 4 10\n",
      "192\t103\t0.0\t2\t2 3 98\n",
      "193\t23\t0.0\t2\t1 5 17\n",
      "194\t6\t0.0\t2\t0 0 6\n",
      "195\t27\t0.0\t2\t5 5 17\n",
      "196\t147\t0.0\t2\t1 0 146\n",
      "197\t33\t0.0\t2\t25 4 4\n",
      "198\t44\t0.0\t2\t2 10 32\n",
      "199\t7\t0.0\t2\t0 3 4\n",
      "200\t36\t0.0\t2\t2 30 4\n",
      "201\t21\t0.0\t2\t1 1 19\n",
      "202\t10\t0.0\t2\t0 5 5\n",
      "203\t4\t0.0\t2\t0 1 3\n",
      "204\t9\t0.0\t2\t2 1 6\n",
      "205\t62\t0.0\t2\t1 48 13\n",
      "206\t11\t0.0\t2\t0 7 4\n",
      "207\t590\t0.0\t2\t1 1 588\n",
      "208\t18\t0.0\t2\t2 9 7\n",
      "209\t9\t0.0\t2\t1 0 8\n",
      "210\t7\t0.0\t2\t1 3 3\n",
      "211\t214\t0.0\t2\t169 34 11\n",
      "212\t81\t0.0\t2\t53 13 15\n",
      "213\t11\t0.0\t2\t2 4 5\n",
      "214\t8\t0.0\t2\t1 3 4\n",
      "215\t6\t0.0\t2\t3 0 3\n",
      "216\t9\t0.0\t2\t1 3 5\n",
      "217\t17\t0.0\t2\t5 4 8\n",
      "218\t20\t0.0\t2\t0 3 17\n",
      "219\t7\t0.0\t2\t1 1 5\n",
      "220\t220\t0.0\t2\t8 197 15\n",
      "221\t3\t0.0\t2\t0 1 2\n",
      "222\t60\t0.0\t2\t0 32 28\n",
      "223\t91\t0.0\t2\t4 6 81\n",
      "224\t58\t0.0\t2\t0 2 56\n",
      "225\t22\t0.0\t2\t5 0 17\n",
      "226\t23\t0.0\t2\t2 4 17\n",
      "227\t6\t0.0\t2\t3 0 3\n",
      "228\t6\t0.0\t2\t3 2 1\n",
      "229\t4\t0.0\t2\t1 1 2\n",
      "230\t7\t0.0\t2\t1 1 5\n",
      "231\t40\t0.0\t2\t3 0 37\n",
      "232\t99\t0.0\t2\t31 19 49\n",
      "233\t8\t0.0\t2\t1 2 5\n",
      "234\t8\t0.0\t2\t4 2 2\n",
      "235\t19\t0.0\t2\t2 6 11\n",
      "236\t14\t0.0\t2\t7 0 7\n",
      "237\t15\t0.0\t2\t1 3 11\n",
      "238\t13\t0.0\t2\t1 5 7\n",
      "239\t30\t0.0\t2\t0 4 26\n",
      "240\t13\t0.0\t2\t1 4 8\n",
      "241\t12\t0.0\t2\t3 1 8\n",
      "242\t19\t0.0\t2\t2 1 16\n",
      "243\t12\t0.0\t2\t1 2 9\n",
      "244\t22\t0.0\t2\t1 7 14\n",
      "245\t21\t0.0\t2\t0 15 6\n",
      "246\t6\t0.0\t2\t2 1 3\n",
      "247\t20\t0.0\t2\t2 0 18\n",
      "248\t217\t0.0\t2\t1 15 201\n",
      "249\t14\t0.0\t2\t2 4 8\n",
      "250\t16\t0.0\t2\t8 3 5\n",
      "251\t121\t0.0\t2\t2 103 16\n",
      "This is cutadapt 3.4 with Python 3.8.8\n",
      "Command line parameters: -a TTACCGCGGCKGCTGGCAC -o /home/backup_files/raw_reads/NIFA.Cassi.2022/modified/read2_noprimer.fastq /home/backup_files/raw_reads/NIFA.Cassi.2022/modified/read2_mod.fastq\n",
      "Processing reads on 1 core in single-end mode ...\n",
      "[8<----------] 00:02:17    17,197,051 reads  @      8.0 µs/read;   7.49 M reads/minute\n",
      "Finished in 137.70 s (8 µs/read; 7.49 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:              17,197,051\n",
      "Reads with adapters:                   104,407 (0.6%)\n",
      "Reads written (passing filters):    17,197,051 (100.0%)\n",
      "\n",
      "Total basepairs processed: 4,316,459,801 bp\n",
      "Total written (filtered):  4,315,689,333 bp (100.0%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: TTACCGCGGCKGCTGGCAC; Type: regular 3'; Length: 19; Trimmed: 104407 times\n",
      "\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-19 bp: 1\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 21.4%\n",
      "  C: 46.1%\n",
      "  G: 13.6%\n",
      "  T: 18.9%\n",
      "  none/other: 0.1%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t42368\t268703.9\t0\t42368\n",
      "4\t35518\t67176.0\t0\t35518\n",
      "5\t16293\t16794.0\t0\t16293\n",
      "6\t943\t4198.5\t0\t943\n",
      "7\t576\t1049.6\t0\t576\n",
      "8\t108\t262.4\t0\t108\n",
      "9\t172\t65.6\t0\t167 5\n",
      "10\t260\t16.4\t1\t179 81\n",
      "11\t82\t4.1\t1\t51 31\n",
      "12\t130\t1.0\t1\t84 46\n",
      "13\t52\t0.3\t1\t43 9\n",
      "14\t156\t0.1\t1\t103 53\n",
      "15\t63\t0.0\t1\t45 18\n",
      "16\t14\t0.0\t1\t10 4\n",
      "17\t15\t0.0\t1\t12 3\n",
      "18\t90\t0.0\t1\t23 67\n",
      "19\t16\t0.0\t1\t14 2\n",
      "20\t30\t0.0\t1\t21 9\n",
      "21\t14\t0.0\t1\t12 2\n",
      "22\t42\t0.0\t1\t29 13\n",
      "23\t238\t0.0\t1\t158 80\n",
      "24\t288\t0.0\t1\t29 259\n",
      "25\t98\t0.0\t1\t72 26\n",
      "26\t105\t0.0\t1\t30 75\n",
      "27\t412\t0.0\t1\t223 189\n",
      "28\t1129\t0.0\t1\t763 366\n",
      "29\t455\t0.0\t1\t320 135\n",
      "30\t1254\t0.0\t1\t878 376\n",
      "31\t308\t0.0\t1\t214 94\n",
      "32\t28\t0.0\t1\t19 9\n",
      "33\t121\t0.0\t1\t76 45\n",
      "34\t24\t0.0\t1\t20 4\n",
      "35\t15\t0.0\t1\t11 4\n",
      "36\t119\t0.0\t1\t79 40\n",
      "37\t17\t0.0\t1\t9 8\n",
      "38\t27\t0.0\t1\t20 7\n",
      "39\t7\t0.0\t1\t4 3\n",
      "40\t6\t0.0\t1\t3 3\n",
      "41\t57\t0.0\t1\t41 16\n",
      "42\t342\t0.0\t1\t258 84\n",
      "43\t7\t0.0\t1\t5 2\n",
      "44\t53\t0.0\t1\t37 16\n",
      "45\t81\t0.0\t1\t63 18\n",
      "46\t75\t0.0\t1\t55 20\n",
      "47\t171\t0.0\t1\t138 33\n",
      "48\t143\t0.0\t1\t113 30\n",
      "49\t46\t0.0\t1\t38 8\n",
      "50\t11\t0.0\t1\t10 1\n",
      "51\t16\t0.0\t1\t12 4\n",
      "52\t52\t0.0\t1\t35 17\n",
      "53\t7\t0.0\t1\t4 3\n",
      "54\t4\t0.0\t1\t2 2\n",
      "55\t6\t0.0\t1\t5 1\n",
      "56\t9\t0.0\t1\t6 3\n",
      "57\t12\t0.0\t1\t9 3\n",
      "58\t5\t0.0\t1\t5\n",
      "59\t16\t0.0\t1\t12 4\n",
      "60\t26\t0.0\t1\t8 18\n",
      "61\t295\t0.0\t1\t255 40\n",
      "62\t7\t0.0\t1\t3 4\n",
      "64\t4\t0.0\t1\t4\n",
      "65\t5\t0.0\t1\t5\n",
      "66\t11\t0.0\t1\t7 4\n",
      "68\t2\t0.0\t1\t1 1\n",
      "69\t1\t0.0\t1\t0 1\n",
      "70\t20\t0.0\t1\t12 8\n",
      "71\t20\t0.0\t1\t18 2\n",
      "72\t6\t0.0\t1\t4 2\n",
      "73\t3\t0.0\t1\t3\n",
      "74\t4\t0.0\t1\t4\n",
      "76\t7\t0.0\t1\t5 2\n",
      "77\t48\t0.0\t1\t38 10\n",
      "78\t14\t0.0\t1\t11 3\n",
      "79\t3\t0.0\t1\t2 1\n",
      "80\t4\t0.0\t1\t3 1\n",
      "81\t4\t0.0\t1\t3 1\n",
      "82\t5\t0.0\t1\t4 1\n",
      "83\t1\t0.0\t1\t1\n",
      "84\t22\t0.0\t1\t20 2\n",
      "85\t78\t0.0\t1\t57 21\n",
      "86\t31\t0.0\t1\t25 6\n",
      "87\t117\t0.0\t1\t99 18\n",
      "88\t1\t0.0\t1\t1\n",
      "90\t4\t0.0\t1\t4\n",
      "93\t1\t0.0\t1\t0 1\n",
      "94\t5\t0.0\t1\t4 1\n",
      "95\t4\t0.0\t1\t1 3\n",
      "96\t7\t0.0\t1\t7\n",
      "97\t5\t0.0\t1\t3 2\n",
      "98\t1\t0.0\t1\t1\n",
      "99\t4\t0.0\t1\t2 2\n",
      "100\t19\t0.0\t1\t18 1\n",
      "101\t4\t0.0\t1\t3 1\n",
      "102\t1\t0.0\t1\t0 1\n",
      "104\t1\t0.0\t1\t0 1\n",
      "105\t23\t0.0\t1\t20 3\n",
      "106\t19\t0.0\t1\t14 5\n",
      "107\t6\t0.0\t1\t5 1\n",
      "109\t1\t0.0\t1\t1\n",
      "110\t9\t0.0\t1\t8 1\n",
      "111\t1\t0.0\t1\t1\n",
      "112\t4\t0.0\t1\t3 1\n",
      "113\t1\t0.0\t1\t1\n",
      "114\t26\t0.0\t1\t24 2\n",
      "115\t4\t0.0\t1\t1 3\n",
      "116\t3\t0.0\t1\t0 3\n",
      "117\t3\t0.0\t1\t1 2\n",
      "118\t1\t0.0\t1\t0 1\n",
      "119\t3\t0.0\t1\t3\n",
      "120\t1\t0.0\t1\t0 1\n",
      "121\t77\t0.0\t1\t65 12\n",
      "122\t43\t0.0\t1\t31 12\n",
      "124\t15\t0.0\t1\t14 1\n",
      "125\t1\t0.0\t1\t1\n",
      "126\t1\t0.0\t1\t1\n",
      "128\t1\t0.0\t1\t0 1\n",
      "130\t2\t0.0\t1\t2\n",
      "131\t1\t0.0\t1\t0 1\n",
      "132\t1\t0.0\t1\t0 1\n",
      "135\t2\t0.0\t1\t0 2\n",
      "137\t3\t0.0\t1\t2 1\n",
      "138\t1\t0.0\t1\t1\n",
      "139\t2\t0.0\t1\t1 1\n",
      "140\t6\t0.0\t1\t1 5\n",
      "143\t1\t0.0\t1\t0 1\n",
      "144\t149\t0.0\t1\t129 20\n",
      "145\t6\t0.0\t1\t5 1\n",
      "146\t3\t0.0\t1\t3\n",
      "147\t1\t0.0\t1\t0 1\n",
      "148\t2\t0.0\t1\t1 1\n",
      "150\t3\t0.0\t1\t3\n",
      "151\t2\t0.0\t1\t2\n",
      "153\t1\t0.0\t1\t1\n",
      "154\t2\t0.0\t1\t2\n",
      "155\t2\t0.0\t1\t1 1\n",
      "156\t4\t0.0\t1\t2 2\n",
      "157\t13\t0.0\t1\t11 2\n",
      "158\t12\t0.0\t1\t8 4\n",
      "159\t3\t0.0\t1\t3\n",
      "160\t4\t0.0\t1\t1 3\n",
      "162\t1\t0.0\t1\t0 1\n",
      "163\t1\t0.0\t1\t0 1\n",
      "164\t4\t0.0\t1\t1 3\n",
      "165\t2\t0.0\t1\t1 1\n",
      "166\t1\t0.0\t1\t0 1\n",
      "171\t6\t0.0\t1\t4 2\n",
      "172\t3\t0.0\t1\t3\n",
      "173\t14\t0.0\t1\t10 4\n",
      "174\t8\t0.0\t1\t2 6\n",
      "175\t4\t0.0\t1\t2 2\n",
      "177\t102\t0.0\t1\t86 16\n",
      "178\t9\t0.0\t1\t0 9\n",
      "179\t1\t0.0\t1\t0 1\n",
      "180\t3\t0.0\t1\t1 2\n",
      "181\t4\t0.0\t1\t2 2\n",
      "182\t2\t0.0\t1\t1 1\n",
      "183\t1\t0.0\t1\t1\n",
      "184\t3\t0.0\t1\t0 3\n",
      "185\t4\t0.0\t1\t1 3\n",
      "186\t3\t0.0\t1\t0 3\n",
      "187\t2\t0.0\t1\t1 1\n",
      "188\t12\t0.0\t1\t8 4\n",
      "189\t1\t0.0\t1\t1\n",
      "191\t3\t0.0\t1\t1 2\n",
      "192\t2\t0.0\t1\t1 1\n",
      "193\t1\t0.0\t1\t1\n",
      "195\t5\t0.0\t1\t4 1\n",
      "196\t1\t0.0\t1\t1\n",
      "197\t17\t0.0\t1\t7 10\n",
      "198\t5\t0.0\t1\t2 3\n",
      "199\t1\t0.0\t1\t0 1\n",
      "200\t2\t0.0\t1\t2\n",
      "201\t1\t0.0\t1\t1\n",
      "204\t1\t0.0\t1\t1\n",
      "205\t3\t0.0\t1\t0 3\n",
      "207\t1\t0.0\t1\t1\n",
      "209\t6\t0.0\t1\t1 5\n",
      "211\t1\t0.0\t1\t0 1\n",
      "212\t4\t0.0\t1\t3 1\n",
      "213\t4\t0.0\t1\t1 3\n",
      "214\t2\t0.0\t1\t2\n",
      "215\t2\t0.0\t1\t0 2\n",
      "216\t2\t0.0\t1\t1 1\n",
      "220\t23\t0.0\t1\t11 12\n",
      "221\t1\t0.0\t1\t0 1\n",
      "222\t5\t0.0\t1\t0 5\n",
      "223\t1\t0.0\t1\t0 1\n",
      "224\t1\t0.0\t1\t0 1\n",
      "225\t3\t0.0\t1\t2 1\n",
      "226\t2\t0.0\t1\t0 2\n",
      "227\t3\t0.0\t1\t1 2\n",
      "228\t4\t0.0\t1\t0 4\n",
      "229\t1\t0.0\t1\t0 1\n",
      "230\t1\t0.0\t1\t0 1\n",
      "231\t3\t0.0\t1\t1 2\n",
      "232\t33\t0.0\t1\t27 6\n",
      "233\t1\t0.0\t1\t1\n",
      "234\t5\t0.0\t1\t3 2\n",
      "235\t2\t0.0\t1\t0 2\n",
      "236\t7\t0.0\t1\t2 5\n",
      "237\t3\t0.0\t1\t0 3\n",
      "238\t1\t0.0\t1\t0 1\n",
      "239\t2\t0.0\t1\t0 2\n",
      "241\t4\t0.0\t1\t1 3\n",
      "243\t2\t0.0\t1\t1 1\n",
      "244\t1\t0.0\t1\t0 1\n",
      "245\t2\t0.0\t1\t0 2\n",
      "246\t1\t0.0\t1\t1\n",
      "247\t2\t0.0\t1\t1 1\n",
      "248\t2\t0.0\t1\t1 1\n",
      "250\t6\t0.0\t1\t1 5\n",
      "251\t60\t0.0\t1\t0 60\n"
     ]
    }
   ],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    read1 = library[3]\n",
    "    read2 = library[4]\n",
    "    \n",
    "    !cutadapt -a ATTAGAWACCCBDGTAGTCC -o $raw/modified/read1_noprimer.fastq $raw/modified/read1_mod.fastq\n",
    "    !cutadapt -a TTACCGCGGCKGCTGGCAC -o $raw/modified/read2_noprimer.fastq $raw/modified/read2_mod.fastq\n",
    "    \n",
    "    # Delete unneeded intermediate files\n",
    "    !rm $raw/modified/read*_mod.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Filter short reads\n",
    "\n",
    "Remove sequences with from primer-removed data with less than 100 bp from all files (too short).\n",
    "\n",
    "SLOW STEP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    os.system(' '.join([\n",
    "        \"python /home/cassi/scripts/qiime2_filter_shortreads.py\",\n",
    "        raw+\"/modified/\"\n",
    "    ]))\n",
    "    \n",
    "    # Remove unneeded intermediate files\n",
    "    !rm $raw/modified/*_noprimer.fastq\n",
    "    !rm $raw/modified/index*_mod.fastq\n",
    "    \n",
    "    # Recompress modified read files\n",
    "    !pigz $raw/modified/read*_filtered.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Concatenate barcodes\n",
    "\n",
    "This step calls a custom script, \"concatenate_barcodes_qiime2.py\". The script must be shuttled to the command line instead of run directly in jupyter notebooks because jupyter has memory issues that truncates the barcodes file without an error (I think).\n",
    "\n",
    "This script requires your index1 and index2 files to be named index1_mod.fastq and index2_mod.fastq and be located in a directory within the raw read directory called 'modified'. This should have been taken care of in earlier steps in this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"python /home/cassi/scripts/qiime2_concatenate_barcodes.py\",\n",
    "        raw+\"/modified\"]))\n",
    "  \n",
    "    # Recompress modified index files and newly created barcodes.fastq file\n",
    "    !pigz $raw/modified/*.fastq   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Move raw data to library directories\n",
    "\n",
    "Creates intermediate directory in library directory. All subsequent files except for the final files will be placed there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    proc = library[1]\n",
    "    raw = library[2]\n",
    "    \n",
    "    # Create output directory if it doesn't exist already\n",
    "    if not os.path.isdir(os.path.join(proc, \"intermediate\")):\n",
    "        !mkdir $proc/intermediate\n",
    "    \n",
    "    # Create a symbolic link to the read data\n",
    "    # QIIME2 import requires a directory containing files named: forward.fastq.gz, reverse.fastq.gz and barcodes.fastq.gz \n",
    "    !ln -s $raw/modified/read1_filtered.fastq.gz $proc/intermediate/forward.fastq.gz\n",
    "    !ln -s $raw/modified/read2_filtered.fastq.gz $proc/intermediate/reverse.fastq.gz\n",
    "    \n",
    "    # Move concatenated barcodes to project directory\n",
    "    !cp $raw/modified/barcodes.fastq.gz $proc/intermediate/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Import into QIIME2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime tools import\",\n",
    "        \"--type EMPPairedEndSequences\",\n",
    "        \"--input-path \"+proc+\"/intermediate\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"+name+\".qza\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Demultiplex\n",
    "\n",
    "The barcode you supply to QIIME is now a concatenation of your forward and reverse barcode. Your 'forward' barcode is actually the reverse complement of your reverse barcode and the 'reverse' is your forward barcode.\n",
    "\n",
    "Slow step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime demux emp-paired\",\n",
    "        \"--m-barcodes-file \"+proc+\"/\"+metadata,\n",
    "        \"--m-barcodes-column BarcodeSequence\",\n",
    "        \"--p-no-golay-error-correction\",\n",
    "        \"--i-seqs \"+proc+\"/intermediate/\"+name+\".qza\",\n",
    "        \"--o-per-sample-sequences \"+proc+\"/intermediate/\"+name+\".demux\",\n",
    "        \"--o-error-correction-details \"+proc+\"/intermediate/\"+name+\".demux-details.qza\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Visualize quality scores\n",
    "\n",
    "Drop output from below command into https://view.qiime2.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime demux summarize\",\n",
    "        \"--i-data \"+proc+\"/intermediate/\"+name+\".demux.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".demux.qzv\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Trimming parameters | USER INPUT REQUIRED\n",
    "\n",
    "Based on the quality scores of the bp along the reads, choose trim and truncate values for the forward and reverse reads. Trim refers to the start of a sequence and truncate the total length (i.e. number of bases to remove from end).\n",
    "\n",
    "All trimming parameters must be the same for datasets that will be directly compared to one-another because ASVs are determined, in part, by sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input your trimming parameters into a python dictionary for all libraries\n",
    "# trim_dict = {\"LibraryName1\":[trim_forward, truncate_forward, trim_reverse, truncate_reverse],\n",
    "#              \"LibraryName2\":[trim_forward, truncate_forward, trim_reverse, truncate_reverse],\n",
    "#               etc...}\n",
    "\n",
    "# The example in the Atacama Desert Tutorial trims 13 bp from the start of each read and does not remove any bases from the end of the 150 bp reads:\n",
    "#  --p-trim-left-f 13 \\  \n",
    "#  --p-trim-left-r 13 \\\n",
    "#  --p-trunc-len-f 150 \\\n",
    "#  --p-trunc-len-r 150\n",
    "\n",
    "trim_dict = {\"NIFA\":[15,220,15,220]} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Trim, denoise and join (aka 'merge') reads using DADA2\n",
    "\n",
    "See the [QIIME2 dada2 denoise-paired documentation](https://docs.qiime2.org/2021.8/plugins/available/dada2/denoise-paired/) for the default parameters used.\n",
    "\n",
    "Slow step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime dada2 denoise-paired\",\n",
    "        \"--i-demultiplexed-seqs \"+proc+\"/intermediate/\"+name+\".demux.qza\",\n",
    "        \"--o-table \"+proc+\"/intermediate/\"+name+\".table.qza\",\n",
    "        \"--o-representative-sequences \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "        \"--o-denoising-stats \"+proc+\"/intermediate/\"+name+\".denoising-stats.qza\",\n",
    "        \"--p-trim-left-f \"+str(trim_dict[name][0]),\n",
    "        \"--p-trim-left-r \"+str(trim_dict[name][2]),\n",
    "        \"--p-trunc-len-f \"+str(trim_dict[name][1]),\n",
    "        \"--p-trunc-len-r \"+str(trim_dict[name][3]),\n",
    "        \"--p-n-threads\",\n",
    "        str(processors)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime metadata tabulate\",\n",
    "        \"--m-input-file \"+proc+\"/NIFA/intermediate/\"+name+\".denoising-stats.qza\",\n",
    "        \"--o-visualization \"+proc+\"/NIFA/intermediate/\"+name+\".denoising-stats.qzv\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12: Create summary of ASVs\n",
    "\n",
    "Drop outputs from below command into https://view.qiime2.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime feature-table summarize\",\n",
    "        \"--i-table \"+proc+\"/intermediate/\"+name+\".table.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".table.qzv\",\n",
    "        \"--m-sample-metadata-file \"+proc+\"/\"+metadata\n",
    "    ]))\n",
    "\n",
    "    os.system(' '.join([\n",
    "        \"qiime feature-table tabulate-seqs\",\n",
    "        \"--i-data \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".rep-seqs.qzv\"\n",
    "    ])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 13: Classify sequences\n",
    "\n",
    "Different QIIME2 versions can conflict with certain classifier database versions. This section will likely need to be updated. Download the latest classifiers here: https://docs.qiime2.org/2021.4/data-resources/\n",
    "\n",
    "* Using SILVA v138 pre-built classifier trained on scikit learn 0.24.1.\n",
    "\n",
    "View output in https://view.qiime2.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use classifier for chosen database\n",
    "try:\n",
    "    if db == \"GreenGenes\":\n",
    "        classifier_db = \"/home/db/GreenGenes/qiime2_13.8.99_515.806_nb.classifier.qza\" # out of date\n",
    "    else:\n",
    "        classifier_db = \"~/databases/silva/silva-138-99-515-806-nb-classifier.qza\"\n",
    "except:\n",
    "        classifier_db = \"~/databases/silva/silva-138-99-515-806-nb-classifier.qza\"\n",
    "        \n",
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "    domain = library[8]\n",
    "\n",
    "    # Classify\n",
    "    if domain == 'bacteria':\n",
    "        os.system(' '.join([\n",
    "            \"qiime feature-classifier classify-sklearn\",\n",
    "            \"--i-classifier\",\n",
    "            classifier_db,\n",
    "            \"--i-reads \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "            \"--o-classification \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "            \"--p-n-jobs\",\n",
    "            str(processors)\n",
    "        ]))\n",
    "\n",
    "    if domain == 'fungi':\n",
    "        os.system(' '.join([\n",
    "            \"qiime feature-classifier classify-sklearn\",\n",
    "            \"--i-classifier /home/db/UNITE/qiime2_unite_ver7.99_20.11.2016_classifier.qza\", # out of date\n",
    "            \"--i-reads \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "            \"--o-classification \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "            \"--p-n-jobs\",\n",
    "            str(processors)\n",
    "        ]))\n",
    "\n",
    "    # Output summary\n",
    "    os.system(' '.join([\n",
    "        \"qiime metadata tabulate\",\n",
    "        \"--m-input-file \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".taxonomy-summary.qzv\"\n",
    "    ])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 14: Combine representative sequences for tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bacteria\n",
    "\n",
    "# Create representative sequences file\n",
    "repseqsbac = []\n",
    "\n",
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    domain = library[8]\n",
    "    \n",
    "    # Create list of rep seq files\n",
    "    if domain == \"bacteria\":\n",
    "        repseqsbac.append(\"--i-data \" + os.path.join(proc, \"intermediate\", name+\".rep-seqs.qza\"))\n",
    "\n",
    "# Create tree directory\n",
    "if not os.path.isdir(os.path.join(project, \"tree\")):\n",
    "    !mkdir $project/tree\n",
    "    \n",
    "# Merge rep sequences from all bacterial libraries for tree\n",
    "os.system(' '.join([\n",
    "    \"qiime feature-table merge-seqs\",\n",
    "    \" \".join(repseqsbac),\n",
    "    \"--o-merged-data \"+project+\"/tree/\"+treename+\".rep-seqs-merged.qza\"\n",
    "]))\n",
    "\n",
    "# Fungi\n",
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    domain = library[8]\n",
    "    \n",
    "    # Create representative sequences file\n",
    "    repseqsfung = []\n",
    "    \n",
    "    if domain == \"fungi\":\n",
    "        repseqsfung.append(\"--i-data \" + os.path.join(proc, \"intermediate\", name+\".rep-seqs.qza\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 15: Make phylogenetic tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    domain = library[8]\n",
    "\n",
    "    if domain == \"bacteria\":\n",
    "        # Generate alignment with MAFFT\n",
    "        os.system(' '.join([\n",
    "            \"qiime alignment mafft\",\n",
    "            \"--i-sequences \"+project+\"/tree/\"+treename+\".rep-seqs-merged.qza\",\n",
    "            \"--o-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned.qza\",\n",
    "            \"--p-n-threads\",\n",
    "            str(processors)\n",
    "        ]))\n",
    "\n",
    "        # Mask hypervariable regions in alignment\n",
    "        os.system(' '.join([\n",
    "            \"qiime alignment mask\",\n",
    "            \"--i-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned.qza\",\n",
    "            \"--o-masked-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned-masked.qza\",\n",
    "        ]))\n",
    "\n",
    "        # Generate tree with FastTree\n",
    "        os.system(' '.join([\n",
    "            \"qiime phylogeny fasttree\",\n",
    "            \"--i-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned-masked.qza\",\n",
    "            \"--o-tree \"+project+\"/tree/\"+treename+\".tree-unrooted.qza\",\n",
    "            \"--p-n-threads\",\n",
    "            str(processors)\n",
    "        ]))\n",
    "\n",
    "        # Root the tree\n",
    "        os.system(' '.join([\n",
    "            \"qiime phylogeny midpoint-root\",\n",
    "            \"--i-tree \"+project+\"/tree/\"+treename+\".tree-unrooted.qza\",\n",
    "            \"--o-rooted-tree \"+project+\"/tree/\"+treename+\".tree-rooted.qza\"\n",
    "        ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 16: Reformat taxonomy\n",
    "\n",
    "Define function to tidy the taxonomy and make it compatible with phyloseq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_taxonomy(tax_dirty, min_support):\n",
    "    output = open(re.sub(\".tsv\",\"-fixed.tsv\",tax_dirty), \"w\")\n",
    "    \n",
    "    full_rank_length = 7\n",
    "    output.write(\"\\t\".join([\"ASV\",\"Domain\",\"Phylum\",\"Class\",\"Order\",\"Family\",\"Genus\",\"Species\"])+\"\\n\")\n",
    "\n",
    "    with open(tax_dirty, \"r\") as f:\n",
    "        next(f)\n",
    "\n",
    "        for line in f:\n",
    "                line = line.strip()\n",
    "                line = line.split(\"\\t\")\n",
    "\n",
    "                read_id = line[0]\n",
    "                tax_string = line[1]\n",
    "                \n",
    "                ## Remove taxonomy prefixes and underscores (only coded for Silva classifications so far)\n",
    "                if db == \"Silva\":\n",
    "                    tax_string = re.sub(\"[a-z]__\", \"\", tax_string)\n",
    "                    tax_string = re.sub(\"_\", \" \", tax_string)\n",
    "\n",
    "                # Split full rank into ranks\n",
    "                full_rank = tax_string.split(\";\")\n",
    "\n",
    "                ## Identify the lowest classified taxonomic rank\n",
    "                # Account for cases when a taxonomic rank contains an empty space (common in GreenGenes output)\n",
    "                last_classified = full_rank[len(full_rank)-1]            \n",
    "\n",
    "                count = 1\n",
    "                while last_classified == \" \":\n",
    "                    last_classified = full_rank[len(full_rank)-count]\n",
    "                    count = count + 1\n",
    "\n",
    "                # Annotate the last classified as 'putative' if it does not meet the minimum support criteria\n",
    "                if float(line[2]) < float(min_support):\n",
    "                        full_rank[full_rank.index(last_classified)] = \"putative \"+last_classified\n",
    "                        last_classified = \"putative \"+last_classified\n",
    "\n",
    "                # Add in columns containing unclassified taxonomic information\n",
    "                for n in range(full_rank.index(last_classified)+1, full_rank_length, 1):               \n",
    "                    try:\n",
    "                        full_rank[n] = \"unclassified \"+last_classified\n",
    "                    except:\n",
    "                        full_rank.append(\"unclassified \"+last_classified)\n",
    "\n",
    "                # Write taxonomy to file\n",
    "                output.write(read_id+\"\\t\"+'\\t'.join(full_rank)+\"\\n\")\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 17: Export from QIIME2\n",
    "\n",
    "All final files will be placed in 'final' directory in library directories. Final tree will be in a 'tree' directory in the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "\n",
    "    # Final output paths\n",
    "    fasta_final = proc+\"/final/\"+name+\".rep-seqs-final.fasta\"\n",
    "    tax_final= proc+\"/final/\"+name+\".taxonomy-final.tsv\"\n",
    "    count_final = proc+\"/final/\"+name+\".counts-final.biom\"\n",
    "    \n",
    "    # Make final data directories\n",
    "    if not os.path.isdir(os.path.join(proc, \"final\")):\n",
    "        !mkdir $proc/final\n",
    "        \n",
    "    # Export ASV table\n",
    "    os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+proc+\"/intermediate/\"+name+\".table.qza\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"\n",
    "    ]))\n",
    "\n",
    "    # Export taxonomic classifications\n",
    "    os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"\n",
    "    ]))\n",
    "    \n",
    "    # Reformat classifications  \n",
    "    format_taxonomy(proc+\"/intermediate/taxonomy.tsv\", min_support)\n",
    "\n",
    "    # Export representative sequences\n",
    "    os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"\n",
    "    ]))\n",
    "    \n",
    "    # Rename exported files and move to final directory\n",
    "    !mv $proc/intermediate/dna-sequences.fasta $fasta_final\n",
    "    !mv $proc/intermediate/feature-table.biom $count_final\n",
    "    !mv $proc/intermediate/taxonomy-fixed.tsv $tax_final\n",
    "    \n",
    "    # Reformat count table\n",
    "    tmp_tsv = re.sub(name+\".counts-final.biom\", \"tmp.tsv\", count_final)\n",
    "    tmp2_tsv = re.sub(name+\".counts-final.biom\", \"tmp2.tsv\", count_final)\n",
    "    count_tsv = re.sub(\".biom\", \".tsv\", count_final)\n",
    "    !biom convert -i $count_final -o $tmp_tsv --to-tsv # conver to .tsv\n",
    "    !tail -n +2 $tmp_tsv > $tmp2_tsv # remove header\n",
    "    !sed 's/\\#OTU ID/ASV/g' $tmp2_tsv > $count_tsv # replace OTU with ASV\n",
    "    !rm $tmp_tsv\n",
    "    !rm $tmp2_tsv\n",
    "    \n",
    "# Export tree\n",
    "os.system(' '.join([\n",
    "    \"qiime tools export\",\n",
    "    \"--input-path \"+project+\"/tree/\"+treename+\".tree-rooted.qza\",\n",
    "    \"--output-path \"+project+\"/tree/\"\n",
    "]))\n",
    "\n",
    "# Rename tree file\n",
    "tree_final = project+\"/tree/\"+treename+\".tree-final.nwk\"\n",
    "!mv $project/tree/\"tree.nwk\" $tree_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export tree\n",
    "os.system(' '.join([\n",
    "    \"qiime tools export\",\n",
    "    \"--input-path \"+project+\"/tree/\"+treename+\".tree-rooted.qza\",\n",
    "    \"--output-path \"+project+\"/tree/\"\n",
    "]))\n",
    "\n",
    "# Rename tree file\n",
    "tree_final = project+\"/tree/\"+treename+\".tree-final.nwk\"\n",
    "!mv $project/tree/\"tree.nwk\" $tree_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qiime tools export --input-path /home/cassi/NIFA/data_amplicon/tree/NIFA.rep-seqs-merged.qza --output-path /home/cassi/NIFA/data_amplicon/tree/\n"
     ]
    }
   ],
   "source": [
    "# Export merged rep seqs\n",
    "os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+project+\"/tree/\"+treename+\".rep-seqs-merged.qza\",\n",
    "        \"--output-path \"+project+\"/tree/\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
